{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dva_sdhdf_combine\n",
    "import imp\n",
    "import os\n",
    "import subprocess\n",
    "import h5py\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "import datetime\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import HourLocator as HourLocator\n",
    "from matplotlib.dates import MinuteLocator as MinuteLocator\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from astropy import units as u\n",
    "from astropy.time import TimeDelta\n",
    "from ipywidgets import interact\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "#### Change the directory to where the files are located\" ####\n",
    "day ='25'\n",
    "directory = '../DVA/Data_Files/DVA_Day_Surveys/'\n",
    "\n",
    "### Change the scan details to your current scan\n",
    "# df = 0.5        \n",
    "# dt = 6.9444431574083865e-06\n",
    "\n",
    "#TODO: actually do the scan properties definition in the beginning\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the file listing azimuth scan start and stop times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052 2022-07-04T03:57:53.110 2022-07-04T04:15:55.184\n",
      "2565 2022-07-04T04:20:37.406 2022-07-04T04:38:39.310\n",
      "2566 2022-07-04T04:40:22.266 2022-07-04T04:58:24.003\n",
      "1271 2022-07-04T05:03:42.716 2022-07-04T05:21:44.818\n",
      "1272 2022-07-04T05:23:27.291 2022-07-04T05:41:29.292\n",
      "2857 2022-07-04T05:48:35.269 2022-07-04T06:06:37.317\n",
      "0124 2022-07-04T06:11:19.190 2022-07-04T06:29:21.101\n",
      "1637 2022-07-04T06:34:03.920 2022-07-04T06:52:06.005\n",
      "0342 2022-07-04T06:57:23.897 2022-07-04T07:15:25.930\n",
      "1927 2022-07-04T07:21:55.804 2022-07-04T07:39:58.034\n",
      "1928 2022-07-04T07:42:16.530 2022-07-04T08:00:18.319\n",
      "2001 2022-07-04T08:03:48.814 2022-07-04T08:21:51.062\n",
      "2002 2022-07-04T08:24:09.373 2022-07-04T08:42:11.545\n",
      "2075 2022-07-04T08:45:41.821 2022-07-04T09:03:44.188\n",
      "2148 2022-07-04T09:07:50.625 2022-07-04T09:25:52.832\n",
      "2149 2022-07-04T09:27:35.229 2022-07-04T09:45:37.044\n",
      "2150 2022-07-04T09:47:56.026 2022-07-04T10:05:57.828\n",
      "2151 2022-07-04T10:07:40.752 2022-07-04T10:25:42.662\n",
      "2152 2022-07-04T10:27:25.410 2022-07-04T10:45:27.414\n",
      "2153 2022-07-04T10:47:46.110 2022-07-04T11:05:48.028\n",
      "0858 2022-07-04T11:10:30.298 2022-07-04T11:28:32.281\n",
      "0859 2022-07-04T11:30:50.747 2022-07-04T11:48:52.934\n",
      "2372 2022-07-04T11:53:35.348 2022-07-04T12:11:37.677\n"
     ]
    }
   ],
   "source": [
    "scan_id = []    # The scan id number\n",
    "scan_start = []  # Start time of the scan (UTC)\n",
    "scan_stop = []   # Stop time of the scan (UTC)\n",
    "\n",
    "# Read in the data and store it in arrays:\n",
    "with open(directory+'DVAsurvey_phase1_day0'+day+'.txt') as fp:\n",
    "    for line in fp:       \n",
    "        scan_id.append(int(line.split()[0]))\n",
    "        scan_start.append(line.split()[1]+'T'+line.split()[2][0:12])\n",
    "        scan_stop.append(line.split()[3]+'T'+line.split()[4][0:12])\n",
    "        \n",
    "# Print out the scan numbers with their start and stop times:\n",
    "for i in range(0,len(scan_id)):\n",
    "    print(f\"{scan_id[i]:04}\",scan_start[i],scan_stop[i])\n",
    "\n",
    "# Convert start and stop times to Modified Julian Day (MJD).\n",
    "# This is needed for plotting and for selecting out data collected\n",
    "# between particular times:\n",
    "scan_start_mjd = Time(scan_start, format='isot',scale='utc').mjd\n",
    "scan_stop_mjd  = Time(scan_stop,  format='isot',scale='utc').mjd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in scan files and stich them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052\n",
      "<HDF5 file \"dva_survey_raw_scan_1052.h5\" (mode r)>\n",
      "2565\n",
      "<HDF5 file \"dva_survey_raw_scan_2565.h5\" (mode r)>\n",
      "2566\n",
      "<HDF5 file \"dva_survey_raw_scan_2566.h5\" (mode r)>\n",
      "1271\n",
      "<HDF5 file \"dva_survey_raw_scan_1271.h5\" (mode r)>\n",
      "1272\n",
      "<HDF5 file \"dva_survey_raw_scan_1272.h5\" (mode r)>\n"
     ]
    }
   ],
   "source": [
    "t_set = []\n",
    "az_set = []\n",
    "dec_set = []\n",
    "ra_set = []\n",
    "el_set = []\n",
    "noise_set = []\n",
    "trim_flag = []\n",
    "\n",
    "scan0 = f\"{scan_id[0]:04}\"\n",
    "\n",
    "# Use one of the scans to get the list of frequencies:\n",
    "freq_channel_increment = 1 #TODO: I'll have to change this to 1 once I am sure I'm reading the data correctly\n",
    "\n",
    "file = h5py.File(directory+'dva_survey_raw_scan_'+scan0+'.h5','r')\n",
    "freq = file['data']['beam_0']['band_SB0']['frequency'][::freq_channel_increment]/1e6\n",
    "df = freq[1] - freq[0]\n",
    "\n",
    "# Create empty arrays for the power data:\n",
    "RR_set = np.empty([0,len(freq)])\n",
    "LL_set = np.empty([0,len(freq)])\n",
    "reRL_set = np.empty([0,len(freq)])\n",
    "imRL_set = np.empty([0,len(freq)])\n",
    "\n",
    "# Loop through all the scans in the \"scan_num\" list:\n",
    "for i in scan_id[0:5]:\n",
    "    print(i)\n",
    "    # select the file:\n",
    "    file = h5py.File(directory+'dva_survey_raw_scan_'+f\"{i:04}\"+'.h5','r')\n",
    "    print(file)\n",
    "    \n",
    "    # access the correct location in the file structure:\n",
    "    dataset = file['data']['beam_0']['band_SB0']['scan_0']\n",
    "    \n",
    "    # Add the position and time data to the corresponding arrays:\n",
    "    dec_set = np.concatenate([dec_set,dataset['metadata']['declination']])\n",
    "    ra_set = np.concatenate([ra_set,dataset['metadata']['right_ascension']])\n",
    "    el_set = np.concatenate([el_set,dataset['metadata']['elevation']])\n",
    "    az_set = np.concatenate([az_set,dataset['metadata']['azimuth']])\n",
    "    t_set = np.concatenate([t_set,dataset['metadata']['utc']])\n",
    "    noise_set = np.concatenate([noise_set,dataset['metadata']['noise_state']]) #This is a \"mask\" for noise regions 1 = noise 0=all good\n",
    "    trim_flag = np.concatenate([trim_flag,dataset['metadata']['trim_scan_flag']])\n",
    "    \n",
    "    # Add the spectrometer power data to the corresponding arrays:\n",
    "    RR_set = np.concatenate([RR_set,dataset['data'][:,0,::freq_channel_increment]],axis=0)\n",
    "    LL_set = np.concatenate([LL_set,dataset['data'][:,1,::freq_channel_increment]],axis=0)\n",
    "    reRL_set = np.concatenate([reRL_set,dataset['data'][:,2,::freq_channel_increment]],axis=0)\n",
    "    imRL_set = np.concatenate([imRL_set,dataset['data'][:,3,::freq_channel_increment]],axis=0)\n",
    "    \n",
    "t_plt = Time(t_set, format='isot',scale='utc').mjd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polarized Intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarized = []\n",
    "for i,j in zip(reRL_set,imRL_set):\n",
    "    PI = np.sqrt((i**2)+(j**2))\n",
    "    polarized.append(PI)\n",
    "polarized_set = np.array(polarized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW RFI_Excision functions (WORK IN PROGRESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power_array has time and frequency\n",
    "#TODO: Count how long it takes to run this for a single frequency \n",
    "\n",
    "# def Find_Slope(array, idx):\n",
    "#     return array[idx+2] - array[idx]\n",
    "def Find_Slope(y_array, x_array, idx):\n",
    "    return (y_array[idx+2] - y_array[idx])/(x_array[idx+2] - x_array[idx])\n",
    "\n",
    "def Is_Time_RFI(in_power_array, threshold, idx, interval_start, interval_end):\n",
    "    retVal = False\n",
    "    in_power_mean = np.nanmean(in_power_array[interval_start:interval_end])\n",
    "    in_power_std = np.nanstd(in_power_array[interval_start:interval_end])\n",
    "    if abs(in_power_array[idx]) > abs(in_power_mean)+threshold*in_power_std:\n",
    "        retVal = True\n",
    "    return retVal\n",
    "\n",
    "\n",
    "\n",
    "def Get_RFI_Duration(time_array, in_power_array, interval_start, interval_end):  #NOTE: This approach might have issues if the interval has a nan on it\n",
    "    #Find the first slope\n",
    "    first_slope = Find_Slope(in_power_array, time_array, interval_start)\n",
    "    #Initiate the RFI interval indexes at the boundaries of the set\n",
    "    RFI_start = interval_start\n",
    "    RFI_end = interval_end\n",
    "    #Initiate as the fastest rise & fall\n",
    "    steepest_rise = first_slope\n",
    "    steepest_fall = first_slope \n",
    "    start_idx = interval_start + 1  # Ignores the first slope (since it's already calculated)\n",
    "    end_idx = interval_end - 2      # Avoids overflowing (since each slope is calculated 2 indexes ahead)\n",
    "    for idx in range(start_idx, end_idx):\n",
    "        current_slope = Find_Slope(in_power_array, time_array, idx)\n",
    "        if(current_slope >  steepest_rise):\n",
    "            steepest_rise = current_slope\n",
    "            RFI_start = idx\n",
    "        elif(current_slope < steepest_fall):\n",
    "            steepest_fall = current_slope\n",
    "            RFI_end = idx + 2\n",
    "    return (RFI_end - RFI_start)\n",
    "\n",
    "#TODO: Change the name of the function below to Find_RFI_Excision_Regions, or make a wrapper function to go through all the frequencies\n",
    "\n",
    "# def Get_RFI_Excision_Mask(time_array, power_array, time_steps, slope_threshold, starting_frequency): #TODO: The final function will not take starting_frequency as an input, I'll loop through all frequencies\n",
    "#     confirmed_RFI_events = Find_RFI_Excision_Intervals(time_array, power_array, time_steps, slope_threshold, starting_frequency)\n",
    "#     mask = []\n",
    "#     #TODO: Populate mask\n",
    "#     return mask\n",
    "def RFI_Time_Scan(time_array, single_freq_power_array, time_steps, threshold):\n",
    "    possible_RFI_events = []\n",
    "    start_idx = time_steps\n",
    "    end_idx = len(time_array)-time_steps              \n",
    "    for idx in range(start_idx, end_idx):\n",
    "        if Is_Time_RFI(single_freq_power_array, threshold, idx, idx - time_steps, idx + time_steps):\n",
    "            RFI_duration = Get_RFI_Duration(time_array, single_freq_power_array, idx - time_steps, idx + time_steps)\n",
    "            possible_RFI_events.append([idx, RFI_duration])\n",
    "    return(possible_RFI_events)\n",
    "\n",
    "def Spectrum_RFI_Start_Found(time_array, spectrum_power_array, idx, slope_threshold):\n",
    "    RFI_Start_Found = False\n",
    "    spectrum_gradient = np.gradient(spectrum_power_array, 3)\n",
    "    current_slope = spectrum_gradient[idx-1]              #Find_Slope(spectrum_power_array, time_array, idx)\n",
    "    next_slope = spectrum_gradient[idx]#Find_Slope(spectrum_power_array, time_array, idx+3)\n",
    "    if((current_slope <= slope_threshold) and (next_slope >= slope_threshold)):\n",
    "        RFI_Start_Found = True\n",
    "        # print(\"RFI start information:\\n - current slope:\", current_slope,\"next slope:\", next_slope, \"Slope threshold:\", slope_threshold)\n",
    "    return RFI_Start_Found\n",
    "\n",
    "def Spectrum_RFI_End_Found(time_array, spectrum_power_array, idx, slope_threshold):\n",
    "    RFI_End_Found = False\n",
    "    spectrum_gradient = np.gradient(spectrum_power_array, 3)\n",
    "    spectrum_large_gradient = np.gradient(spectrum_power_array, 10)\n",
    "    flatness_ratio = 0.5\n",
    "    current_slope = spectrum_gradient[idx-1]            #Find_Slope(spectrum_power_array, time_array, idx)\n",
    "    # next_slope = spectrum_gradient[idx]           #Find_Slope(spectrum_power_array, time_array, idx+3)\n",
    "    next_slope = spectrum_large_gradient[idx]           #Find_Slope(spectrum_power_array, time_array, idx+3)\n",
    "    if((current_slope <= (-1)*slope_threshold) and (next_slope >= (-flatness_ratio)*slope_threshold) and (next_slope <= (flatness_ratio)*slope_threshold)):\n",
    "        RFI_End_Found = True\n",
    "        # print(\"RFI end information:\\n - current slope:\", current_slope,\"next slope:\", next_slope, \"Slope threshold:\", slope_threshold)\n",
    "    return RFI_End_Found\n",
    "\n",
    "def RFI_Spectrum_Scan(time_array, spectrum_power_array, freq_idx, slope_threshold): #NOTE: This might be an issue if I have a nan value on my array\n",
    "    scan_bandwidth = 50 #[MHz]\n",
    "    start_idx = int(freq_idx - int((scan_bandwidth/df)/2))  #This changes the bandwidth from MHz to idxes\n",
    "    end_idx = int(freq_idx + int((scan_bandwidth/df)/2))\n",
    "    RFI_confirmed = False\n",
    "    RFI_spectral_thickness = 0\n",
    "    for rfi_start_idx in range(start_idx, end_idx):                                             #Scan over the entire bandwith interval\n",
    "        if(Spectrum_RFI_Start_Found(time_array, spectrum_power_array, rfi_start_idx, slope_threshold)):     #If I found the starting pattern\n",
    "            for rfi_end_idx in range(rfi_start_idx, end_idx):                                   #Finish looking at the bandwidth interval looking for the end\n",
    "                if(Spectrum_RFI_End_Found(time_array, spectrum_power_array, rfi_end_idx, slope_threshold)):     #If I found the ending pattern          TODO: I have a problem in the end found algorithm\n",
    "                    RFI_confirmed = True      \n",
    "                    break\n",
    "                    # RFI_spectral_thickness = (rfi_end_idx - rfi_start_idx)\n",
    "                else:\n",
    "                    continue\n",
    "            if(RFI_confirmed):                                                                          #and stop looping throught the interval for efficiency\n",
    "                break\n",
    "        else:\n",
    "            rfi_end_idx = end_idx\n",
    "    return RFI_confirmed, rfi_start_idx, (rfi_end_idx)#RFI_spectral_thickness\n",
    "    \n",
    "def find_nearest_idx(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "def Find_RFI_Regions(time_array, power_array, time_steps, slope_threshold, starting_frequency):\n",
    "    confirmed_RFI_events = []\n",
    "    # mask = np.zeros([len(time_array)])  #Initiate empty mask\n",
    "    # freq_measured = np.min(np.where(abs(freq-starting_frequency)<df))#[0][0] #[MHz]\n",
    "    freq_idx = find_nearest_idx(freq, starting_frequency)\n",
    "    freq_measured = freq[freq_idx]\n",
    "    print(\"input starting frequency:\", starting_frequency)\n",
    "    print(\"closest frequency measured:\", freq_measured)\n",
    "    \n",
    "    gaussian_threshold = 3  #Arbitrary, changed as needed\n",
    "    possible_RFI_events = RFI_Time_Scan(time_array, power_array[:, freq_idx], time_steps, gaussian_threshold) #Returns an array with [idx, RFI_idx_duration] of candidate RFI signals\n",
    "    print(\"possible RFI events:\", len(possible_RFI_events))\n",
    "    for event in range(len(possible_RFI_events)):\n",
    "        dt = (time_array[1] - time_array[0])\n",
    "        RFI_event_time_idx = possible_RFI_events[event][0]              #in [idxes]\n",
    "        RFI_event_duration = possible_RFI_events[event][1]*(dt)         #in [time_units]\n",
    "        #Confirms by doing a small spectrum scan\n",
    "        RFI_event_confirmation_result = RFI_Spectrum_Scan(time_array, power_array[RFI_event_time_idx, :], freq_idx, slope_threshold) #Returns [bools, rfi_start_idx, rfi_end_idx]_______________old:[bool, rfi_start_idx, idx_spectral_thickness]\n",
    "        # print(\"RFI\", event ,\"starts at:\", freq[RFI_event_confirmation_result[1]],\"ends at:\", freq[RFI_event_confirmation_result[2]])\n",
    "        if(RFI_event_confirmation_result[0]):\n",
    "            print(\"RFI\", event, \"was confirmed\")\n",
    "            # confirmed_RFI_events.append([freq_measured, RFI_event_confirmation_result[1]*df, time_array[possible_RFI_events[event][0]], RFI_event_duration])\n",
    "            confirmed_RFI_events.append([freq[RFI_event_confirmation_result[1]], (RFI_event_confirmation_result[2] - RFI_event_confirmation_result[1])*df, time_array[possible_RFI_events[event][0]], RFI_event_duration])\n",
    "            #TODO: Run the RFI_Spectrum_Scan_Sweep to find the borders of the RFI duration\n",
    "    print(\"confirmed RFI events:\", len(confirmed_RFI_events))\n",
    "    return confirmed_RFI_events #An Array with [freq, df, time, dt] for each confirmed RFI\n",
    "\n",
    "###################################################################################################################################################################\n",
    "# in_power_array        Input power array (RR, LL, reRL, imRL) at a single frequency TODO: This needs to change to \n",
    "# numt                  Number of time points to include in the 'window' in which the standard deviation is calculated\n",
    "# threshold             Array of standard deviation thresholds to use in each stage of the RFI excision \n",
    "\n",
    "def Get_Polarized_Set(reRL_set, imRL_set, freq_measured):\n",
    "    polarized = []\n",
    "    reRL_set_in_use = reRL_set[:,freq_measured]    #TODO: maybe I can try making something general that I can scan over all frequencies\n",
    "    imRL_set_in_use = imRL_set[:,freq_measured]\n",
    "    for i,j in zip(reRL_set_in_use,imRL_set_in_use):\n",
    "        PI = np.sqrt((i**2)+(j**2))\n",
    "        polarized.append(PI)\n",
    "    return np.array(polarized)\n",
    "\n",
    "\n",
    "def Apply_RFI_Excision_Mask(mask, input_array): #TODO: This needs to be updated to implement all frequencies\n",
    "    \n",
    "    masked_copy = input_array.copy()\n",
    "    for idx in range(0, len(input_array)-1):\n",
    "        if(mask[idx] == 1):\n",
    "            masked_copy[idx] = np.nan\n",
    "    return(masked_copy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b62fdd6faa46eaa427ec04f2d85ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=True, description='waterfall_enabled'), Output()), _dom_classes=('widget-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.DVA_Visualization(waterfall_enabled)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = freq[1]-freq[0]\n",
    "\n",
    "def DVA_Waterfall_View():\n",
    "    #TODO: Add another DVA_Waterfall interactive_function such that I can change between LL_Set, RR_set, etc...\n",
    "    power_min = 70\n",
    "    power_max = 78\n",
    "\n",
    "    fig,axs = plt.subplots(1,1,figsize=(15,10)) \n",
    "    fs = 16\n",
    "\n",
    "    im = axs.imshow(10.*np.log10(LL_set.T),aspect='auto',vmin=power_min,vmax=power_max,origin='lower',\n",
    "                extent=[t_plt[0],t_plt[-1],freq[0],freq[-1]])\n",
    "\n",
    "    divider = make_axes_locatable(axs)\n",
    "    cax = divider.append_axes('right', size='2%', pad=0.05)\n",
    "    cbar = fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "    cbar.ax.tick_params(labelsize=fs) \n",
    "    cbar.set_label('Power (dB)', fontsize=fs)\n",
    "\n",
    "    axs.set_xlim(t_plt[0],t_plt[-1])\n",
    "    axs.set_ylim(freq[0],freq[-1])\n",
    "    axs.tick_params(axis='both', labelsize=fs)\n",
    "    axs.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    axs.fmt_xdata = mdates.DateFormatter('%H:%M:%S')\n",
    "    axs.set_xlabel('Time (UTC)',fontsize=fs)        \n",
    "    axs.set_ylabel('Frequency (MHz)',fontsize=fs)\n",
    "\n",
    "\n",
    "def DVA_Cross_Sections(freq_chosen, time_idx, freq_cross_section):\n",
    "    freq_measured = np.where(abs(freq-freq_chosen)<df)[0][0]\n",
    "\n",
    "    fs = 12    \n",
    "    fig,axs1 = plt.subplots(1,1,figsize=(16,6))  \n",
    "    # TODO: use the log of LL_set_clean\n",
    "    if(freq_cross_section):\n",
    "        axs1.plot(freq, LL_set[time_idx,:], label = 'LL_set with polarized mask')\n",
    "        axs1.vlines(freq_chosen, 0 , 100e9, color = 'red')\n",
    "        axs1.set_ylim(np.min(LL_set[:,freq_measured]), np.max(LL_set[time_idx,:]))\n",
    "        axs1.set_xlabel('Frequency',fontsize=fs)\n",
    "        axs1.set_ylabel('Power',fontsize=fs)\n",
    "    else:\n",
    "        axs1.plot(t_plt, LL_set[:,freq_measured], label = 'LL_set unmasked RFI')\n",
    "        axs1.vlines(t_plt[time_idx], 0 , 100e9, color = 'red')\n",
    "\n",
    "        axs1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "        axs1.set_ylim(np.min(LL_set[:,freq_measured]), np.max(LL_set[:,freq_measured]))\n",
    "        axs1.fmt_xdata = mdates.DateFormatter('%H:%M:%S')\n",
    "        axs1.set_xlabel('Time (UTC)',fontsize=fs)\n",
    "        axs1.set_ylabel('Power',fontsize=fs)\n",
    "        axs1.legend()\n",
    "\n",
    "def DVA_Visualization(waterfall_enabled):\n",
    "    if waterfall_enabled:\n",
    "        interact(DVA_Waterfall_View)\n",
    "    else:\n",
    "        interact(DVA_Cross_Sections, freq_chosen = (350, 1000, df), freq_cross_section = False, time_idx = (0,len(t_plt)-1))\n",
    "\n",
    "\n",
    "interact(DVA_Visualization, waterfall_enabled = True)\n",
    "\n",
    "#TODO: plot power in DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the flagging visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e88630cf0d43709d68d3e3d792f9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='rfi_region_chosen', max=10), Output()), _dom_classes=('w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.Flagging_Visualization(rfi_region_chosen)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Flagging_Visualization(rfi_region_chosen):\n",
    "    time_steps = 30\n",
    "    slope_threshold = 1e7 #This number needs to be adjusted in order to correctly filter out non-RFI NOTE: 5000 works\n",
    "    freq_chosen = 845\n",
    "    polarized_Set_RFI_Regions = Find_RFI_Regions(t_plt, polarized_set, time_steps, slope_threshold, freq_chosen) #Returns an array of [freq, df, time, dt]1\n",
    "    RFI_region = polarized_Set_RFI_Regions[rfi_region_chosen]\n",
    "\n",
    "    print(\"real df is:\", freq[1] - freq[0])\n",
    "\n",
    "    #Try plotting the first RFI_Region\n",
    "\n",
    "    power_min = 69\n",
    "    power_max = 75\n",
    "\n",
    "    time_framing = 25\n",
    "    freq_framing = 4#2\n",
    "\n",
    "    t1_plt = RFI_region[2]# - RFI_region[3]\n",
    "    t2_plt = RFI_region[2] + RFI_region[3]\n",
    "    t1_plt_framed = RFI_region[2] - RFI_region[3]*time_framing\n",
    "    t2_plt_framed = RFI_region[2] + RFI_region[3]*time_framing\n",
    "\n",
    "    freq1 = RFI_region[0]# - RFI_region[1]\n",
    "    freq2 = RFI_region[0] + RFI_region[1]\n",
    "    freq1_framed = RFI_region[0] - freq_framing\n",
    "    freq2_framed = RFI_region[0] + RFI_region[1]*freq_framing\n",
    "    ######################################\n",
    "    rfi_start_idx = find_nearest_idx(t_plt, t1_plt)\n",
    "    rfi_end_idx = find_nearest_idx(t_plt, t2_plt)\n",
    "    rfi_start_idx_framed = find_nearest_idx(t_plt, t1_plt_framed)\n",
    "    rfi_end_idx_framed = find_nearest_idx(t_plt, t2_plt_framed)\n",
    "\n",
    "    f_plt_start_idx = find_nearest_idx(freq, freq1)\n",
    "    f_plt_end_idx = find_nearest_idx(freq, freq2)\n",
    "    f_plt_start_idx_framed = find_nearest_idx(freq, freq1_framed)\n",
    "    f_plt_end_idx_framed = find_nearest_idx(freq, freq2_framed)\n",
    "\n",
    "\n",
    "    # PLOTTING THE CROSS-SECTIONS ------------------------------------------------------------------------------------------------\n",
    "    freq_idx = find_nearest_idx(freq, freq_chosen)\n",
    "    rfi_halfway_time = int((rfi_start_idx + rfi_end_idx)/2)\n",
    "    fig,axs1 = plt.subplots(1,2,figsize=(15,5)) \n",
    "\n",
    "    axs1[0].plot(t_plt[rfi_start_idx_framed: rfi_end_idx_framed], LL_set[rfi_start_idx_framed: rfi_end_idx_framed, freq_idx], label = 'LL_set')\n",
    "    axs1[0].plot(t_plt[rfi_start_idx: rfi_end_idx], LL_set[rfi_start_idx: rfi_end_idx, freq_idx], label = 'RFI Selected')\n",
    "    axs1[0].set_xlabel('Time (UTC)',fontsize=12)\n",
    "    axs1[0].xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    axs1[0].set_ylabel('Power',fontsize=12)\n",
    "\n",
    "    axs1[1].plot(freq[f_plt_start_idx_framed: f_plt_end_idx_framed], LL_set[rfi_halfway_time,f_plt_start_idx_framed: f_plt_end_idx_framed], '-ok', label = 'LL_set', color = 'blue')\n",
    "    axs1[1].plot(freq[f_plt_start_idx: f_plt_end_idx], LL_set[rfi_halfway_time,f_plt_start_idx: f_plt_end_idx], '-ok', label = 'RFI Selected', color = 'orange')\n",
    "    axs1[1].set_xlabel('Frequency',fontsize=12)\n",
    "    axs1[1].set_ylabel('Power',fontsize=12)\n",
    "\n",
    "    axs1[0].legend()\n",
    "    axs1[1].legend()\n",
    "    #--------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    # PLOTTING WATERFALL RFI ------------------------------------------------------------------------------------------------------\n",
    "    RFI_duration_time = t_plt[rfi_start_idx_framed: rfi_end_idx_framed]\n",
    "    RFI_freq_bandwith = freq[f_plt_start_idx_framed: f_plt_end_idx_framed]\n",
    "\n",
    "\n",
    "    fig,axs = plt.subplots(1,1,figsize=(15,10)) \n",
    "    fs = 16\n",
    "\n",
    "    # Create a Rectangle patch ---------------------------------------------------------------------------------------------------\n",
    "    RFI_detected = patches.Rectangle((t_plt[rfi_start_idx], freq[f_plt_start_idx]), t_plt[rfi_end_idx] - t_plt[rfi_start_idx], freq[f_plt_end_idx] - freq[f_plt_start_idx], linewidth=1, edgecolor='r', facecolor='none')\n",
    "    # Add the patch to the Axes0\n",
    "    axs.add_patch(RFI_detected)\n",
    "    # ---------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    im = axs.imshow(10.*np.log10(LL_set[rfi_start_idx_framed: rfi_end_idx_framed,f_plt_start_idx_framed: f_plt_end_idx_framed].T),aspect='auto',vmin=power_min,vmax=power_max,origin='lower',\n",
    "                extent=[RFI_duration_time[0],RFI_duration_time[-1],RFI_freq_bandwith[0],RFI_freq_bandwith[-1]])\n",
    "\n",
    "    divider = make_axes_locatable(axs)\n",
    "    cax = divider.append_axes('right', size='2%', pad=0.05)\n",
    "    cbar = fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "    cbar.ax.tick_params(labelsize=fs) \n",
    "    cbar.set_label('Power (dB)', fontsize=fs)\n",
    "\n",
    "    axs.set_xlim(RFI_duration_time[0],RFI_duration_time[-1])\n",
    "    # axs.set_ylim(RFI_freq_bandwith[0],RFI_freq_bandwith[-1])\n",
    "    axs.tick_params(axis='both', labelsize=fs)\n",
    "    axs.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    axs.fmt_xdata = mdates.DateFormatter('%H:%M:%S')\n",
    "    axs.set_xlabel('Time (UTC)',fontsize=fs)        \n",
    "    axs.set_ylabel('Frequency (MHz)',fontsize=fs)\n",
    "\n",
    "\n",
    "    #TODO: I don't think it's clear which region this method is flaggin as RFI\n",
    "\n",
    "\n",
    "# Flagging_Visualization(0)\n",
    "\n",
    "interact(Flagging_Visualization, rfi_region_chosen = (0,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future notes:\n",
    "\n",
    "I think the algorighm should use primarily the frequency sweep to determine the shape of the RFI.\n",
    "\n",
    "steps:\n",
    "- Work on the frequency bandwidth algorithm\n",
    "- Repeat that frequency sweep over time and use it to determine the duration of the RFI, since the \"gaussian\" shape of the RFI is very unreliable\n",
    "\n",
    "\n",
    "### Anna's comment:\n",
    "- Ignore the noise beacon using the file. There's an notebook that does that already"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
