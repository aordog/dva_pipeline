{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6980991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.interpolate import griddata\n",
    "from astropy.time import Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba0ae78",
   "metadata": {},
   "source": [
    "## Define functions used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in each data scan at selected frequency index\n",
    "def read_file(dir_in,filename,f_idx):\n",
    "\n",
    "    dva_file = fits.open(dir_in+filename)\n",
    "\n",
    "    t = np.empty(len(dva_file[1].data))\n",
    "    az = np.empty(len(dva_file[1].data))\n",
    "    el = np.empty(len(dva_file[1].data))\n",
    "    RA = np.empty(len(dva_file[1].data))\n",
    "    dec = np.empty(len(dva_file[1].data))\n",
    "    StokesI = np.empty(len(dva_file[1].data))\n",
    "    StokesQ = np.empty(len(dva_file[1].data))\n",
    "    StokesU = np.empty(len(dva_file[1].data))\n",
    "    date_mjd = np.empty(len(dva_file[1].data))\n",
    "    \n",
    "    for i in range(0,len(t)):\n",
    "        date = dva_file[1].data[i][2]+'T00:00:00.0'\n",
    "        date_mjd[i] = Time(date, format='isot',scale='utc').mjd\n",
    "        az[i] = dva_file[1].data[i][13]\n",
    "        el[i] = dva_file[1].data[i][14]\n",
    "        RA[i] = dva_file[1].data[i][11]\n",
    "        dec[i] = dva_file[1].data[i][12]\n",
    "        t[i] = dva_file[1].data[i][7]\n",
    "        StokesI[i] = dva_file[1].data[i][8][0][0][0][f_idx]\n",
    "        StokesQ[i] = dva_file[1].data[i][8][0][0][1][f_idx]\n",
    "        StokesU[i] = dva_file[1].data[i][8][0][0][2][f_idx] \n",
    "\n",
    "    return az, el, RA, dec, t, StokesI, StokesQ, StokesU, date_mjd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9313ff",
   "metadata": {},
   "source": [
    "## Establish directories and frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecbb49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "#  Pick the scan directory and whether we want East or West scans\n",
    "####################################################################\n",
    "freqrange = 'second' # 'second'=higher frequencies, 'first'=lower frequencies\n",
    "elrange = 'low'      # replace with 'high' for high elevation scans\n",
    "EW = 'W'\n",
    "####################################################################\n",
    "\n",
    "scan_list = 'scan_list_'+elrange+'el.txt'\n",
    "dir_in = '/srv/data/dva/New_mini_survey_'+freqrange+'_half_'+elrange+'/'\n",
    "\n",
    "freqs = []\n",
    "with open(dir_in+'ListOfFrequencies.txt') as f:\n",
    "    for line in f:\n",
    "        freqs.append(float(line.split()[0]))\n",
    "\n",
    "# Use this printout of the frequencies to chose which channel to read in:\n",
    "for i in range(0,len(freqs)):\n",
    "    print(i,freqs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff6d103",
   "metadata": {},
   "source": [
    "## Pick the frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "f_idx = 8\n",
    "###################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc259bc5",
   "metadata": {},
   "source": [
    "## Read in data for selected frequency and set of scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01314a7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Reading in files for f = '+str(freqs[f_idx])+' MHz...')\n",
    "print('----------------------------------------')\n",
    "print('')\n",
    "az_all = []\n",
    "el_all = []\n",
    "RA_all = []\n",
    "dec_all = []\n",
    "t_all = []\n",
    "I = []\n",
    "Q = []\n",
    "U = []\n",
    "date_mjd_all = []\n",
    "\n",
    "i = 0\n",
    "with open(dir_in+scan_list) as f:\n",
    "    for line in f:\n",
    "        if (line[26] == EW):\n",
    "            print(i+1,line.split()[0])\n",
    "            az,el,RA,dec,t,StokesI,StokesQ,StokesU,date_mjd = read_file(dir_in,line.split()[0],f_idx)\n",
    "            az_all.append(az)\n",
    "            el_all.append(el)\n",
    "            RA_all.append(RA)\n",
    "            dec_all.append(dec)\n",
    "            t_all.append(t)\n",
    "            I.append(StokesI)\n",
    "            Q.append(StokesQ)\n",
    "            U.append(StokesU)\n",
    "            date_mjd_all.append(date_mjd)\n",
    "            i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c67a9c",
   "metadata": {},
   "source": [
    "## Turn the lists into arrays (everything is 1D at this point - scan files were just stitched together end to end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2493a5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "az_arr = np.concatenate(az_all)\n",
    "el_arr = np.concatenate(el_all)\n",
    "RA_arr = np.concatenate(RA_all)*360/24 # Convert from hours to degrees\n",
    "dec_arr = np.concatenate(dec_all)\n",
    "I_arr = np.concatenate(I)\n",
    "Q_arr = np.concatenate(Q)\n",
    "U_arr = np.concatenate(U)\n",
    "date_mjd_arr = np.concatenate(date_mjd_all)\n",
    "\n",
    "print(Q_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8b2653",
   "metadata": {},
   "source": [
    "## Median-subtract Q and U (to approximate instrumental polarization offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879b469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_arr_ms = Q_arr-np.nanmedian(Q_arr)\n",
    "U_arr_ms = U_arr-np.nanmedian(U_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106ef2b8",
   "metadata": {},
   "source": [
    "## Pick a grid spacing size (in degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7fbbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "dxy = 0.5\n",
    "#############################\n",
    "numRA = int(360./dxy)\n",
    "numdec= int(180./dxy)\n",
    "\n",
    "print(numRA,numdec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8852d1ea",
   "metadata": {},
   "source": [
    "## Interpolate onto a grid (this may take a few minutes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246bde8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original coordinates for the datapoint positions\n",
    "points = tuple([RA_arr,dec_arr])\n",
    "\n",
    "# A regular grid in RA/dec:\n",
    "ra_reg = np.linspace(0+dxy/2,360-dxy/2,numRA)\n",
    "dec_reg = np.linspace(-90+dxy/2,90-dxy/2,numdec)\n",
    "ra_2D, dec_2D = np.meshgrid(ra_reg, dec_reg)\n",
    "\n",
    "# Flatten the 2D grid in order to match with 1D data format\n",
    "reg_grid = tuple([ra_2D.flatten(),dec_2D.flatten()])\n",
    "\n",
    "# Print out sizes of various arrays and tuples to check\n",
    "print(type(points))\n",
    "print(len(points))\n",
    "print(points[0].shape)\n",
    "print(Q_arr.shape)\n",
    "print(type(reg_grid))\n",
    "print(len(reg_grid))\n",
    "print(reg_grid[0].shape)\n",
    "print('')\n",
    "\n",
    "# Do the interpolation (note: interpolated data are still 1D array at this point)\n",
    "Q_interp_1D = griddata(points,Q_arr_ms,reg_grid,method='linear')\n",
    "U_interp_1D = griddata(points,U_arr_ms,reg_grid,method='linear')\n",
    "\n",
    "print(Q_interp_1D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec6b4f",
   "metadata": {},
   "source": [
    "## Now turn the interpolated data into 2D format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1259d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_interp_2D = np.reshape(Q_interp_1D,ra_2D.shape)[:,::-1]\n",
    "U_interp_2D = np.reshape(U_interp_1D,ra_2D.shape)[:,::-1]\n",
    "\n",
    "print(Q_interp_2D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4b0fb2",
   "metadata": {},
   "source": [
    "## Plot interpolated and original scans (plotting Q for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5523f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,1,figsize=(20,10)) \n",
    "\n",
    "# Use imshow for interpolated data set:\n",
    "im1 = ax[0].imshow(Q_interp_2D,vmin=-15,vmax=15,cmap='RdBu_r',origin='lower',\n",
    "                  extent=[360,0,-90,90])\n",
    "# Use scatterplot for individual scans, since points not on regular grid:\n",
    "im2 = ax[1].scatter(RA_arr,dec_arr,s=0.1,c=Q_arr_ms,vmin=-15,vmax=15,cmap='RdBu_r')\n",
    "\n",
    "divider = make_axes_locatable(ax[0])\n",
    "cax = divider.append_axes(\"right\", size=\"1%\", pad=0.05)\n",
    "plt.colorbar(im1, cax=cax)\n",
    "\n",
    "divider = make_axes_locatable(ax[1])\n",
    "cax = divider.append_axes(\"right\", size=\"1%\", pad=0.05)\n",
    "plt.colorbar(im2, cax=cax)\n",
    "\n",
    "ax[0].set_title('Interpolated')\n",
    "ax[1].set_title('Original scans')\n",
    "\n",
    "for i in range(0,2):\n",
    "    ax[i].set_aspect('equal') \n",
    "    ax[i].set_xlabel('RA')\n",
    "    ax[i].set_ylabel('dec')\n",
    "    ax[i].set_xlim(360,0)\n",
    "    ax[i].set_ylim(-25,65)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ce3bc2",
   "metadata": {},
   "source": [
    "## Create a 2D plate-caree FITS header for writing out files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ec0be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr_car_2D = fits.Header.fromstring(\"\"\"\n",
    "NAXIS   =                    2\n",
    "CUNIT1  = 'deg     '\n",
    "CUNIT2  = 'deg     '\n",
    "\"\"\", sep='\\n')\n",
    "\n",
    "hdr_car_2D['COORDSYS']  = 'icrs'\n",
    "hdr_car_2D['NAXIS1']  = Q_interp_2D.shape[1] \n",
    "hdr_car_2D['NAXIS2']  = Q_interp_2D.shape[0]\n",
    "\n",
    "hdr_car_2D['CTYPE1']  = 'RA---CAR'\n",
    "hdr_car_2D['CRPIX1']  = Q_interp_2D.shape[1]/2.+0.5 \n",
    "hdr_car_2D['CRVAL1']  = 360./2.          \n",
    "hdr_car_2D['CDELT1']  = -dxy\n",
    "\n",
    "hdr_car_2D['CTYPE2']  = 'DEC--CAR'\n",
    "hdr_car_2D['CRPIX2']  = Q_interp_2D.shape[0]/2.+0.5\n",
    "hdr_car_2D['CRVAL2']  = 0.\n",
    "hdr_car_2D['CDELT2']  = dxy\n",
    "\n",
    "print(repr(hdr_car_2D))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b11c662",
   "metadata": {},
   "source": [
    "## Write out files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24ac63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Pick filename and output directory here:\n",
    "outfilename = 'test.fits' # Pick better names! :D \n",
    "outfiledir = '/srv/data/dva/dva_map_test_results/George/'\n",
    "overwrite = True # CAREFUL! If you don't want to accidentally\n",
    "                 # overwrite files, set this to False\n",
    "###########################################################\n",
    "\n",
    "fits.writeto(outfiledir+outfilename,Q_interp_2D,header=hdr_car_2D,\n",
    "             overwrite=overwrite,output_verify='fix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8a05cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
