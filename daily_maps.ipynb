{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb366a5e",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be574a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dva_sdhdf_combine_v3\n",
    "import imp\n",
    "import os\n",
    "import subprocess\n",
    "import h5py\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "import datetime\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import HourLocator as HourLocator\n",
    "from matplotlib.dates import MinuteLocator as MinuteLocator\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from astropy import units as u\n",
    "from astropy.time import TimeDelta\n",
    "from astropy.modeling import models, fitting\n",
    "from astropy.coordinates import SkyCoord,EarthLocation, AltAz, ICRS, Galactic, FK4, FK5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d4ce93",
   "metadata": {},
   "source": [
    "## NOTE: if files containing desired days and frequencies have already been created, skip to \"Read in selected daily map data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003b3ad9",
   "metadata": {},
   "source": [
    "## Select range of days, frequencies, and bandwidth to average over:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e0912",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_list = list(range(1,48))\n",
    "freq_list = [520.0,800.0]\n",
    "freq_width= 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b009a22",
   "metadata": {},
   "source": [
    "## Read in the scan IDs and times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a438cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_id = []    # The scan id number\n",
    "scan_start = []  # Start time of the scan (UTC)\n",
    "scan_stop = []   # Stop time of the scan (UTC)\n",
    "day_array = []\n",
    "\n",
    "# Read in the data and store it in arrays:\n",
    "for day in days_list:\n",
    "    dir_in = '/media/ordoga/DVA_data/survey_phase1_day'+f\"{day:02}\"+'/'\n",
    "    with open(dir_in+'DVAsurvey_phase1_day0'+f\"{day:02}\"+'.txt') as fp:\n",
    "        for line in fp:       \n",
    "            scan_id.append(int(line.split()[0]))\n",
    "            scan_start.append(line.split()[1]+'T'+line.split()[2][0:12])\n",
    "            scan_stop.append(line.split()[3]+'T'+line.split()[4][0:12])\n",
    "            day_array.append(day)\n",
    "        \n",
    "# Print out the scan numbers with their start and stop times:\n",
    "for i in range(0,len(scan_id)):\n",
    "    print(day_array[i],f\"{scan_id[i]:04}\",scan_start[i],scan_stop[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f692d9",
   "metadata": {},
   "source": [
    "## Read in frequency array from one of the scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd4c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan0 = f\"{scan_id[0]:04}\"\n",
    "dir_in = '/media/ordoga/DVA_data/survey_phase1_day'+f\"{days_list[0]:02}\"+'/'\n",
    "file = h5py.File(dir_in+'dva_survey_raw_scan_'+scan0+'.h5','r')\n",
    "freq = file['data']['beam_0']['band_SB0']['frequency'][:]/1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cbb404",
   "metadata": {},
   "source": [
    "## Set up frequencies ranges over which to average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483d54c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_idx = []\n",
    "\n",
    "for freq_pick in freq_list:\n",
    "    freq_idx.append(np.where(abs(freq-freq_pick)<=freq_width/2.)[0])\n",
    "\n",
    "for i in range(0,len(freq_idx)):\n",
    "    print(i)\n",
    "    print(freq[freq_idx[i]])\n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e4d27d",
   "metadata": {},
   "source": [
    "## Set up new data arrays combining all scans and calculate medians for correlation products\n",
    "### Note: will take a LONG time to run! (took over 3 hours for 969 scans at 2 frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac269fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "t_set = []\n",
    "az_set = []\n",
    "dec_set = []\n",
    "ra_set = []\n",
    "el_set = []\n",
    "noise_set = []\n",
    "trim_flag = []\n",
    "\n",
    "# Create empty arrays for the power data:\n",
    "RR_set = np.empty([0,len(freq_idx)])\n",
    "LL_set = np.empty([0,len(freq_idx)])\n",
    "reRL_set = np.empty([0,len(freq_idx)])\n",
    "imRL_set = np.empty([0,len(freq_idx)])\n",
    "    \n",
    "    \n",
    "# Loop through all the scans in the \"scan_num\" list:   \n",
    "for i in range(0,len(scan_id)):\n",
    "    \n",
    "    # select the file:\n",
    "    dir_in = '/media/ordoga/DVA_data/survey_phase1_day'+f\"{day_array[i]:02}\"+'/'\n",
    "    file = h5py.File(dir_in+'dva_survey_raw_scan_'+f\"{scan_id[i]:04}\"+'.h5','r')\n",
    "    print(f\"{i:03}\",f\"{day_array[i]:02}\",f\"{scan_id[i]:04}\",file)\n",
    "    \n",
    "    # access the correct location in the file structure:\n",
    "    dataset = file['data']['beam_0']['band_SB0']['scan_0']\n",
    "    \n",
    "    # Add the position and time data to the corresponding arrays:\n",
    "    dec_set = np.concatenate([dec_set,dataset['metadata']['declination']])\n",
    "    ra_set = np.concatenate([ra_set,dataset['metadata']['right_ascension']])\n",
    "    el_set = np.concatenate([el_set,dataset['metadata']['elevation']])\n",
    "    az_set = np.concatenate([az_set,dataset['metadata']['azimuth']])\n",
    "    t_set = np.concatenate([t_set,dataset['metadata']['utc']])\n",
    "    noise_set = np.concatenate([noise_set,dataset['metadata']['noise_state']])\n",
    "    trim_flag = np.concatenate([trim_flag,dataset['metadata']['trim_scan_flag']])\n",
    "    \n",
    "    RR = np.empty([len(dataset['metadata']['utc']),len(freq_idx)])\n",
    "    LL = np.empty([len(dataset['metadata']['utc']),len(freq_idx)])\n",
    "    reRL = np.empty([len(dataset['metadata']['utc']),len(freq_idx)])\n",
    "    imRL = np.empty([len(dataset['metadata']['utc']),len(freq_idx)])\n",
    "    \n",
    "    for i in range(0,len(freq_idx)):\n",
    "        #print(i)\n",
    "        #print(freq[freq_idx[i]])\n",
    "        RR[:,i] = np.nanmedian(dataset['data'][:,0,freq_idx[i]],axis=1)\n",
    "        LL[:,i] = np.nanmedian(dataset['data'][:,1,freq_idx[i]],axis=1)\n",
    "        reRL[:,i] = np.nanmedian(dataset['data'][:,2,freq_idx[i]],axis=1)\n",
    "        imRL[:,i] = np.nanmedian(dataset['data'][:,3,freq_idx[i]],axis=1)\n",
    "    # Add the spectrometer power data to the corresponding arrays:\n",
    "    RR_set = np.concatenate([RR_set,RR],axis=0)\n",
    "    LL_set = np.concatenate([LL_set,LL],axis=0)\n",
    "    reRL_set = np.concatenate([reRL_set,reRL],axis=0)\n",
    "    imRL_set = np.concatenate([imRL_set,imRL],axis=0)\n",
    "    \n",
    "t_set_plt = Time(t_set, format='isot',scale='utc').mjd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2270a5ed",
   "metadata": {},
   "source": [
    "## Get rid of points where RA=24 artifact occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919161e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_set_trim = ra_set.copy()\n",
    "dec_set_trim = dec_set.copy()\n",
    "az_set_trim = az_set.copy()\n",
    "el_set_trim = el_set.copy()\n",
    "t_set_trim = t_set.copy()\n",
    "t_set_plt_trim = t_set_plt.copy()\n",
    "noise_set_trim = noise_set.copy()\n",
    "RR_set_trim = RR_set.copy()\n",
    "LL_set_trim = LL_set.copy()\n",
    "reRL_set_trim = reRL_set.copy()\n",
    "imRL_set_trim = imRL_set.copy()\n",
    "\n",
    "idxtrim = np.where(trim_flag == 1)[0]\n",
    "#print(idxtrim)\n",
    "\n",
    "ra_set_trim[idxtrim] = np.nan\n",
    "dec_set_trim[idxtrim] = np.nan \n",
    "az_set_trim[idxtrim] = np.nan \n",
    "el_set_trim[idxtrim] = np.nan \n",
    "t_set_trim[idxtrim] = np.nan \n",
    "t_set_plt_trim[idxtrim] = np.nan \n",
    "noise_set_trim[idxtrim] = np.nan \n",
    "RR_set_trim[idxtrim,:] = np.nan \n",
    "LL_set_trim[idxtrim,:] = np.nan \n",
    "reRL_set_trim[idxtrim,:] = np.nan \n",
    "imRL_set_trim[idxtrim,:] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd003175",
   "metadata": {},
   "source": [
    "## Write out all new arrays and parameters to .npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e3a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../DVA2/DATA/Daily_maps/survey_phase1_upto_day'+str(days_list[-1])+'.npy'\n",
    "np.save(filename,([RR_set_trim,LL_set_trim,reRL_set_trim,imRL_set_trim,\n",
    "                    ra_set_trim,dec_set_trim,az_set_trim,el_set_trim,\n",
    "                    t_set_trim,noise_set_trim,t_set_plt_trim,\n",
    "                    day_array,scan_id,scan_start,scan_stop,freq_list,freq_width]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097f0e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ad3031c",
   "metadata": {},
   "source": [
    "## Map-making code starts here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196e202e",
   "metadata": {},
   "source": [
    "## Read in selected daily map data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d82d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../DVA2/DATA/Daily_maps/survey_phase1_upto_day47.npy',allow_pickle=True)\n",
    "\n",
    "RR_set = data[0].astype(float)\n",
    "LL_set = data[1].astype(float)\n",
    "reRL_set = data[2].astype(float)\n",
    "imRL_set = data[3].astype(float)\n",
    "ra_set = data[4].astype(float)\n",
    "dec_set = data[5].astype(float)\n",
    "az_set = data[6].astype(float)\n",
    "el_set = data[7].astype(float)\n",
    "t_set = data[8].copy()\n",
    "noise_set = data[9].astype(float)\n",
    "t_set_plt = data[10].astype(float)\n",
    "day_array = data[11]\n",
    "scan_id = data[12]\n",
    "scan_start = data[13]\n",
    "scan_stop = data[14]\n",
    "freq_list = data[15]\n",
    "ra_set_deg = ra_set*360./24.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b64262d",
   "metadata": {},
   "source": [
    "## Set points when noise source is on to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4286c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbad = np.where(noise_set == 1.0)\n",
    "RR_set[wbad] = np.nan\n",
    "LL_set[wbad] = np.nan\n",
    "reRL_set[wbad] = np.nan\n",
    "imRL_set[wbad] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96d0b6a",
   "metadata": {},
   "source": [
    "## Median subtract reRL and imRL (estimate instrumental pol.) and calculate polarized intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a37482",
   "metadata": {},
   "outputs": [],
   "source": [
    "reRL_set_instr = reRL_set.copy()\n",
    "imRL_set_instr = imRL_set.copy()\n",
    "\n",
    "for i in range(0,len(freq_list)):\n",
    "    reRL_med = np.nanmedian(reRL_set[:,i])\n",
    "    imRL_med = np.nanmedian(imRL_set[:,i])\n",
    "    reRL_set_instr[:,i] = reRL_set_instr[:,i] - reRL_med\n",
    "    imRL_set_instr[:,i] = imRL_set_instr[:,i] - imRL_med\n",
    "\n",
    "PI = np.sqrt(reRL_set_instr**2 + imRL_set_instr**2)\n",
    "PI[wbad] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef3fc7d",
   "metadata": {},
   "source": [
    "## Calculate Galactic coordinates (takes several minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe8b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "loc = EarthLocation(lat = 49.3*u.deg, lon = -119.6*u.deg, height = 546*u.m)\n",
    "\n",
    "wgood = np.where(np.isfinite(el_set))\n",
    "\n",
    "AltAzcoord = SkyCoord(alt=el_set[wgood]*u.deg, az=az_set[wgood]*u.deg, \n",
    "                      obstime=Time(t_set[wgood],format='isot',scale='utc',location=loc),\n",
    "                      frame = 'altaz', location = loc)\n",
    "\n",
    "ra = AltAzcoord.icrs.ra.deg\n",
    "dec = AltAzcoord.icrs.dec.deg\n",
    "\n",
    "l = AltAzcoord.galactic.l.deg\n",
    "b = AltAzcoord.galactic.b.deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57578dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(freq_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541b286c",
   "metadata": {},
   "source": [
    "## Map in equatorial coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9931bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "### Select frequency index to plot:\n",
    "frq_idx = 0\n",
    "\n",
    "### Select data product to plot:\n",
    "data_plot = 10*np.log10(LL_set[wgood,frq_idx])\n",
    "#data_plot = 10*np.log10(RR_set[wgood,frq_idx])\n",
    "#data_plot = PI[wgood,frq_idx]\n",
    "\n",
    "fs=18\n",
    "Pmin = 72\n",
    "Pmax = 78\n",
    "spts = 1\n",
    "######################################################\n",
    "\n",
    "print(freq_list[frq_idx])\n",
    "\n",
    "eq = SkyCoord(ra, dec, frame='icrs', unit=u.deg)\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.subplot(111, projection='aitoff')\n",
    "plt.grid(True)\n",
    "plt.scatter(-eq.ra.wrap_at('180d').radian, eq.dec.radian,s=spts,c=data_plot,vmin=Pmin, vmax=Pmax,alpha=0.4)\n",
    "positions = (-150*np.pi/180.,-120*np.pi/180.,-90*np.pi/180.,-60*np.pi/180.,-30*np.pi/180.,0,\n",
    "             30*np.pi/180.,60*np.pi/180.,90*np.pi/180.,120*np.pi/180.,150*np.pi/180.)\n",
    "labels = (\"10\",\"8\",\"6\",\"4\",\"2\",\"0\",\"22\",\"20\",\"18\",\"16\",\"14\")\n",
    "plt.xticks(positions, labels,fontsize=fs)\n",
    "plt.yticks(fontsize=fs)\n",
    "plt.ylabel('Declination (degrees)',fontsize=fs)\n",
    "plt.xlabel('RA (hours)',fontsize=fs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38e766d",
   "metadata": {},
   "source": [
    "## Map in Galactic coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159df27",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "### Select frequency index to plot:\n",
    "frq_idx = 1\n",
    "\n",
    "### Select data product to plot:\n",
    "#data_plot = 10*np.log10(LL_set[wgood,frq_idx])\n",
    "#data_plot = 10*np.log10(RR_set[wgood,frq_idx])\n",
    "data_plot = PI[wgood,frq_idx]\n",
    "\n",
    "fs=18\n",
    "Pmin = 0\n",
    "Pmax = 2e5\n",
    "spts = 1\n",
    "######################################################\n",
    "\n",
    "gal = SkyCoord(l, b, frame='galactic', unit=u.deg)\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.subplot(111, projection='aitoff')\n",
    "plt.grid(True)\n",
    "plt.scatter(-gal.l.wrap_at('180d').radian, gal.b.radian,s=spts,c=data_plot,vmin=Pmin,vmax=Pmax,alpha=0.4)\n",
    "positions = (-150*np.pi/180.,-120*np.pi/180.,-90*np.pi/180.,-60*np.pi/180.,-30*np.pi/180.,0,\n",
    "             30*np.pi/180.,60*np.pi/180.,90*np.pi/180.,120*np.pi/180.,150*np.pi/180.)\n",
    "labels = (\"150\",\"120\",\"90\",\"60\",\"30\",\"0\",\"330\",\"300\",\"270\",\"240\",\"210\")\n",
    "plt.xticks(positions, labels,fontsize=fs)\n",
    "plt.yticks(fontsize=fs)\n",
    "plt.xlabel('Galactic Longitude (degrees)',fontsize=fs)\n",
    "plt.ylabel('Galactic Latitude (degrees)',fontsize=fs)\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.savefig('../DVA2/PLOTS/survey_phase1_47days_800_gal_PI.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3204520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
