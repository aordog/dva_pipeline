{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do daily visual checks of data quality\n",
    "## L. Caffarello, July 2022\n",
    "### Updates by A. Ordog, August-September 2022\n",
    "### August 25, 2022 (AO): \n",
    "#### - changed filenames to account for survey phases\n",
    "#### - changed frequency channels read in to all channels (instead of every 12th)\n",
    "#### - included 5 MHz to each side of the central frequency in the single-scan, 1D timeseries plots\n",
    "#### - included persistent RFI mask indication (grey background) on timeseries plots\n",
    "### September 12, 2022 (AO):\n",
    "#### - option to mask out persistent RFI\n",
    "#### - indicate elevation of scans\n",
    "#### - scan IDs indicated in waterfall plot columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dva_sdhdf_combine\n",
    "import imp\n",
    "import os\n",
    "import subprocess\n",
    "import h5py\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "import datetime\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import HourLocator as HourLocator\n",
    "from matplotlib.dates import MinuteLocator as MinuteLocator\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from astropy import units as u\n",
    "from astropy.time import TimeDelta\n",
    "from ipywidgets import interact\n",
    "from ipywidgets import interactive_output\n",
    "\n",
    "#### Change the directory to where the files are located\" ####\n",
    "day ='01'\n",
    "directory = '/srv/data/dva/survey_azimuth_scans/'\n",
    "#directory = '/srv/data/dva/survey_azimuth_scans/day_45_lightning/'\n",
    "#directory = '../DVA/Data_Files/DVA_Day_Surveys/'\n",
    "\n",
    "#TODO: actually do the scan properties definition in the beginning\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the file listing azimuth scan start and stop times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0041 2022-06-07T04:16:05.291 2022-06-07T04:34:07.198 49\n",
      "0042 2022-06-07T04:36:26.049 2022-06-07T04:54:28.279 49\n",
      "1555 2022-06-07T04:59:10.310 2022-06-07T05:17:12.390 20\n",
      "0260 2022-06-07T05:21:54.456 2022-06-07T05:39:56.371 49\n",
      "0261 2022-06-07T05:42:15.375 2022-06-07T06:00:17.472 49\n",
      "0262 2022-06-07T06:02:00.228 2022-06-07T06:20:02.213 49\n",
      "0263 2022-06-07T06:21:44.857 2022-06-07T06:39:46.723 49\n",
      "0264 2022-06-07T06:42:05.621 2022-06-07T07:00:07.724 49\n",
      "0265 2022-06-07T07:01:50.183 2022-06-07T07:19:52.104 49\n",
      "1778 2022-06-07T07:24:34.427 2022-06-07T07:42:36.183 20\n",
      "0483 2022-06-07T07:47:54.539 2022-06-07T08:05:56.863 49\n",
      "0484 2022-06-07T08:07:39.391 2022-06-07T08:25:41.423 49\n",
      "1997 2022-06-07T08:30:23.775 2022-06-07T08:48:25.852 20\n",
      "1998 2022-06-07T08:50:08.338 2022-06-07T09:08:10.522 20\n",
      "0703 2022-06-07T09:13:28.600 2022-06-07T09:31:30.723 49\n",
      "0704 2022-06-07T09:33:13.442 2022-06-07T09:51:15.300 49\n",
      "0705 2022-06-07T09:53:33.755 2022-06-07T10:11:36.030 49\n",
      "0706 2022-06-07T10:13:18.543 2022-06-07T10:31:20.739 49\n",
      "0707 2022-06-07T10:33:03.258 2022-06-07T10:51:05.319 49\n",
      "0708 2022-06-07T10:53:24.348 2022-06-07T11:11:26.327 49\n",
      "0709 2022-06-07T11:13:09.029 2022-06-07T11:31:10.927 49\n",
      "2222 2022-06-07T11:35:52.965 2022-06-07T11:53:54.797 20\n",
      "0927 2022-06-07T11:59:13.227 2022-06-07T12:17:15.085 49\n"
     ]
    }
   ],
   "source": [
    "scan_id = []    # The scan id number\n",
    "scan_start = []  # Start time of the scan (UTC)\n",
    "scan_stop = []   # Stop time of the scan (UTC)\n",
    "scan_el = []\n",
    "\n",
    "# Read in the data and store it in arrays:\n",
    "with open(directory+'DVAsurvey_phase1_day0'+day+'.txt') as fp:\n",
    "    for line in fp:       \n",
    "        scan_id.append(int(line.split()[0]))\n",
    "        scan_start.append(line.split()[1]+'T'+line.split()[2][0:12])\n",
    "        scan_stop.append(line.split()[3]+'T'+line.split()[4][0:12])\n",
    "        scan_el.append(line.split()[5][0:2])\n",
    "        \n",
    "# Print out the scan numbers with their start and stop times:\n",
    "for i in range(0,len(scan_id)):\n",
    "    print(f\"{scan_id[i]:04}\",scan_start[i],scan_stop[i],scan_el[i])\n",
    "\n",
    "# Convert start and stop times to Modified Julian Day (MJD).\n",
    "# This is needed for plotting and for selecting out data collected\n",
    "# between particular times:\n",
    "scan_start_mjd = Time(scan_start, format='isot',scale='utc').mjd\n",
    "scan_stop_mjd  = Time(scan_stop,  format='isot',scale='utc').mjd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in scan files and stich them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "<HDF5 file \"dva_survey_phase1_raw_0041.h5\" (mode r)>\n",
      "42\n",
      "<HDF5 file \"dva_survey_phase1_raw_0042.h5\" (mode r)>\n",
      "1555\n",
      "<HDF5 file \"dva_survey_phase1_raw_1555.h5\" (mode r)>\n",
      "260\n",
      "<HDF5 file \"dva_survey_phase1_raw_0260.h5\" (mode r)>\n",
      "261\n",
      "<HDF5 file \"dva_survey_phase1_raw_0261.h5\" (mode r)>\n",
      "262\n",
      "<HDF5 file \"dva_survey_phase1_raw_0262.h5\" (mode r)>\n",
      "263\n",
      "<HDF5 file \"dva_survey_phase1_raw_0263.h5\" (mode r)>\n",
      "264\n",
      "<HDF5 file \"dva_survey_phase1_raw_0264.h5\" (mode r)>\n",
      "265\n",
      "<HDF5 file \"dva_survey_phase1_raw_0265.h5\" (mode r)>\n",
      "1778\n",
      "<HDF5 file \"dva_survey_phase1_raw_1778.h5\" (mode r)>\n",
      "483\n",
      "<HDF5 file \"dva_survey_phase1_raw_0483.h5\" (mode r)>\n",
      "484\n",
      "<HDF5 file \"dva_survey_phase1_raw_0484.h5\" (mode r)>\n",
      "1997\n",
      "<HDF5 file \"dva_survey_phase1_raw_1997.h5\" (mode r)>\n",
      "1998\n",
      "<HDF5 file \"dva_survey_phase1_raw_1998.h5\" (mode r)>\n",
      "703\n",
      "<HDF5 file \"dva_survey_phase1_raw_0703.h5\" (mode r)>\n",
      "704\n",
      "<HDF5 file \"dva_survey_phase1_raw_0704.h5\" (mode r)>\n",
      "705\n",
      "<HDF5 file \"dva_survey_phase1_raw_0705.h5\" (mode r)>\n",
      "706\n",
      "<HDF5 file \"dva_survey_phase1_raw_0706.h5\" (mode r)>\n",
      "707\n",
      "<HDF5 file \"dva_survey_phase1_raw_0707.h5\" (mode r)>\n",
      "708\n",
      "<HDF5 file \"dva_survey_phase1_raw_0708.h5\" (mode r)>\n",
      "709\n",
      "<HDF5 file \"dva_survey_phase1_raw_0709.h5\" (mode r)>\n",
      "2222\n",
      "<HDF5 file \"dva_survey_phase1_raw_2222.h5\" (mode r)>\n",
      "927\n",
      "<HDF5 file \"dva_survey_phase1_raw_0927.h5\" (mode r)>\n"
     ]
    }
   ],
   "source": [
    "t_set = []\n",
    "az_set = []\n",
    "dec_set = []\n",
    "ra_set = []\n",
    "el_set = []\n",
    "noise_set = []\n",
    "trim_flag = []\n",
    "\n",
    "scan0 = f\"{scan_id[0]:04}\"\n",
    "\n",
    "freq_channel_increment = 1 #TODO: I'll have to change this to 1 once I am sure I'm reading the data correctly\n",
    "\n",
    "# Use one of the scans to get the list of frequencies:\n",
    "file = h5py.File(directory+'dva_survey_phase1_raw_'+scan0+'.h5','r')\n",
    "freq = file['data']['beam_0']['band_SB0']['frequency'][::freq_channel_increment]/1e6\n",
    "\n",
    "# Create empty arrays for the power data:\n",
    "RR_set = np.empty([0,len(freq)])\n",
    "LL_set = np.empty([0,len(freq)])\n",
    "reRL_set = np.empty([0,len(freq)])\n",
    "imRL_set = np.empty([0,len(freq)])\n",
    "\n",
    "# Loop through all the scans in the \"scan_num\" list:\n",
    "for i in scan_id:\n",
    "#for i in scan_id[0:5]:\n",
    "    print(i)\n",
    "    # select the file:\n",
    "    file = h5py.File(directory+'dva_survey_phase1_raw_'+f\"{i:04}\"+'.h5','r')\n",
    "    print(file)\n",
    "    \n",
    "    # access the correct location in the file structure:\n",
    "    dataset = file['data']['beam_0']['band_SB0']['scan_0']\n",
    "    \n",
    "    # Add the position and time data to the corresponding arrays:\n",
    "    dec_set = np.concatenate([dec_set,dataset['metadata']['declination']])\n",
    "    ra_set = np.concatenate([ra_set,dataset['metadata']['right_ascension']])\n",
    "    el_set = np.concatenate([el_set,dataset['metadata']['elevation']])\n",
    "    az_set = np.concatenate([az_set,dataset['metadata']['azimuth']])\n",
    "    t_set = np.concatenate([t_set,dataset['metadata']['utc']])\n",
    "    noise_set = np.concatenate([noise_set,dataset['metadata']['noise_state']]) #This is a \"mask\" for noise regions 1 = noise 0=all good\n",
    "    trim_flag = np.concatenate([trim_flag,dataset['metadata']['trim_scan_flag']])\n",
    "    \n",
    "    # Add the spectrometer power data to the corresponding arrays:\n",
    "    RR_set = np.concatenate([RR_set,dataset['data'][:,0,::freq_channel_increment]],axis=0)\n",
    "    LL_set = np.concatenate([LL_set,dataset['data'][:,1,::freq_channel_increment]],axis=0)\n",
    "    reRL_set = np.concatenate([reRL_set,dataset['data'][:,2,::freq_channel_increment]],axis=0)\n",
    "    imRL_set = np.concatenate([imRL_set,dataset['data'][:,3,::freq_channel_increment]],axis=0)\n",
    "    \n",
    "t_plt = Time(t_set, format='isot',scale='utc').mjd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polarized Intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LL_set: (41481, 8250)\n",
      " t_plt: (41481,)\n",
      "  freq: (8250,)\n"
     ]
    }
   ],
   "source": [
    "polarized = []\n",
    "for i,j in zip(reRL_set,imRL_set):\n",
    "    PI = np.sqrt((i**2)+(j**2))\n",
    "    polarized.append(PI)\n",
    "polarized_plot = np.array(polarized)\n",
    "\n",
    "#print(LL_set)\n",
    "print(\"LL_set:\", np.shape(LL_set))\n",
    "print(\" t_plt:\", np.shape(t_plt))\n",
    "print(\"  freq:\", np.shape(freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in persistent RFI mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "RFI_mask_idx = []\n",
    "with open('/srv/data/dva/RFIpersist_mask/RFIpersist_mask.txt') as fp:\n",
    "    for line in fp:\n",
    "        if i>0: \n",
    "            #print(line)\n",
    "            RFI_mask_idx.append(int(line.split()[0]))\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leo's original code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = freq[1]-freq[0]\n",
    "\n",
    "def DVA_Waterfall_View():\n",
    "    #TODO: Add another DVA_Waterfall interactive_function such that I can change between LL_Set, RR_set, etc...\n",
    "    power_min = 66 #AO changed from 70\n",
    "    power_max = 78\n",
    "\n",
    "    fig,axs = plt.subplots(1,1,figsize=(15,10)) \n",
    "    fs = 16\n",
    "    \n",
    "    for i in range(0,len(scan_id)):\n",
    "        w = np.where((t_plt>=scan_start_mjd[i]) & (t_plt<=scan_stop_mjd[i]))[0]\n",
    "        extent = [scan_start_mjd[i],scan_stop_mjd[i],freq[0],freq[-1]]\n",
    "    \n",
    "        im = axs.imshow(10*np.log10(LL_set[w,:].T),aspect='auto',vmin=power_min,vmax=power_max,\n",
    "                        origin='lower',extent=extent,cmap='viridis')\n",
    "    \n",
    "    #im = axs.imshow(10.*np.log10(LL_set.T),aspect='auto',vmin=power_min,vmax=power_max,origin='lower',\n",
    "    #            extent=[t_plt[0],t_plt[-1],freq[0],freq[-1]])\n",
    "\n",
    "    divider = make_axes_locatable(axs)\n",
    "    cax = divider.append_axes('right', size='2%', pad=0.05)\n",
    "    cbar = fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "    cbar.ax.tick_params(labelsize=fs) \n",
    "    cbar.set_label('Power (dB)', fontsize=fs)\n",
    "\n",
    "    axs.set_xlim(t_plt[0],t_plt[-1])\n",
    "    axs.set_ylim(freq[0],freq[-1])\n",
    "    axs.tick_params(axis='both', labelsize=fs)\n",
    "    axs.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    axs.fmt_xdata = mdates.DateFormatter('%H:%M:%S')\n",
    "    axs.set_xlabel('Time (UTC)',fontsize=fs)        \n",
    "    axs.set_ylabel('Frequency (MHz)',fontsize=fs)\n",
    "\n",
    "\n",
    "def DVA_Cross_Sections(freq_chosen, time_idx, freq_cross_section):\n",
    "    freq_measured = np.where(abs(freq-freq_chosen)<df)[0][0]\n",
    "\n",
    "    fs = 12    \n",
    "    fig,axs1 = plt.subplots(1,1,figsize=(16,6))  \n",
    "    # TODO: use the log of LL_set_clean\n",
    "    if(freq_cross_section):\n",
    "        power_min = 66 #AO added limits\n",
    "        power_max = 78\n",
    "        # AO changed to log scale and added RR:\n",
    "        axs1.plot(freq,10*np.log10(LL_set[time_idx,:]), label='LL')\n",
    "        axs1.plot(freq,10*np.log10(RR_set[time_idx,:]), label='RR')\n",
    "        axs1.vlines(freq_chosen, 0 , 100e9, color = 'red')\n",
    "        axs1.set_ylim(power_min,power_max) #AO changed this to log scale limits\n",
    "        axs1.set_xlim(350,1050)\n",
    "        #axs1.set_ylim(np.min(LL_set[:,freq_measured]), np.max(LL_set[time_idx,:]))\n",
    "        axs1.set_xlabel('Frequency',fontsize=fs)\n",
    "    else:\n",
    "        power_min = 66 #AO added limits\n",
    "        power_max = 78\n",
    "        # AO changed to log scale and added RR:\n",
    "        axs1.scatter(t_plt, 10*np.log10(LL_set[:,freq_measured]), label='LL',s=0.5)\n",
    "        axs1.scatter(t_plt, 10*np.log10(RR_set[:,freq_measured]), label='RR',s=0.5)\n",
    "        axs1.vlines(t_plt[time_idx], 0 , 100e9, color = 'red')\n",
    "\n",
    "        axs1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "        axs1.set_ylim(power_min,power_max) #AO changed this to log scale limits\n",
    "        axs1.fmt_xdata = mdates.DateFormatter('%H:%M:%S')\n",
    "        axs1.set_xlabel('Time (UTC)',fontsize=fs)\n",
    "        axs1.set_xlim(t_plt[0],t_plt[-1])\n",
    "    axs1.set_ylabel('Power',fontsize=fs)\n",
    "    axs1.legend()\n",
    "    axs1.grid() # AO added grid\n",
    "\n",
    "def DVA_Visualization(waterfall_enabled):\n",
    "    if waterfall_enabled:\n",
    "        interact(DVA_Waterfall_View)\n",
    "    else:\n",
    "        interact(DVA_Cross_Sections, freq_chosen = (350, 1000, df), freq_cross_section = False, time_idx = (0,len(t_plt)-1))\n",
    "\n",
    "\n",
    "interact(DVA_Visualization, waterfall_enabled = True)\n",
    "\n",
    "#TODO: plot power in DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated visualization, including single-scan option\n",
    "### Changes made by AO:\n",
    "#### - power bounds in dB to see lower power signal\n",
    "#### - changed to log scale and added RR to time series plots and spectra\n",
    "#### - added grids to 1D plots\n",
    "#### - added option for single-scan plots (both waterfall and 1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = freq[1]-freq[0]\n",
    "power_min = 65\n",
    "power_max = 79\n",
    "fs = 14\n",
    "\n",
    "def DVA_Waterfall_View(RFI_masked):  \n",
    "    \n",
    "    #TODO: implement toggling between RR, LL,reRL, imRL\n",
    "       \n",
    "    fig,axs = plt.subplots(1,1,figsize=(15,10)) \n",
    "    \n",
    "    for i in range(0,len(scan_id)):\n",
    "        w = np.where((t_plt>=scan_start_mjd[i]) & (t_plt<=scan_stop_mjd[i]))[0]\n",
    "        extent = [scan_start_mjd[i],scan_stop_mjd[i],freq[0],freq[-1]]\n",
    "        \n",
    "        if scan_el[i] == '49':\n",
    "            textclr = 'blue'\n",
    "        else:\n",
    "            textclr = 'red'\n",
    "                \n",
    "        data_plot = 10*np.log10(LL_set[w,:].T)\n",
    "        if RFI_masked:\n",
    "            data_plot[RFI_mask_idx,:] = np.nan\n",
    "    \n",
    "        im = axs.imshow(data_plot,aspect='auto',vmin=power_min,vmax=power_max,\n",
    "                        origin='lower',extent=extent,cmap='viridis')\n",
    "\n",
    "        axs.text(scan_start_mjd[i]+3e-3,1038,f\"{scan_id[i]:04}\",rotation=45,fontsize=fs,color=textclr)\n",
    "    \n",
    "    divider = make_axes_locatable(axs)\n",
    "    cax = divider.append_axes('right', size='2%', pad=0.05)\n",
    "    cbar = fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "    cbar.ax.tick_params(labelsize=fs) \n",
    "    cbar.set_label('Power (dB)', fontsize=fs)\n",
    "\n",
    "    axs.set_xlim(t_plt[0],t_plt[-1])\n",
    "    axs.set_ylim(freq[0],freq[-1])\n",
    "    axs.tick_params(axis='both', labelsize=fs)\n",
    "    axs.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    axs.fmt_xdata = mdates.DateFormatter('%H:%M:%S')\n",
    "    axs.set_xlabel('Time (UTC)',fontsize=fs)        \n",
    "    axs.set_ylabel('Frequency (MHz)',fontsize=fs)\n",
    "\n",
    "def DVA_Waterfall_View_singlescan(scan_chosen, RFI_masked):\n",
    "    \n",
    "    #TODO: implement toggling between RR, LL,reRL, imRL\n",
    "\n",
    "    fig,axs = plt.subplots(1,1,figsize=(15,10)) \n",
    "    \n",
    "    scan_id_plot = scan_chosen\n",
    "    scan_idx = np.where(np.array(scan_id) == scan_id_plot)\n",
    "    \n",
    "    w = np.where((t_plt>=scan_start_mjd[scan_idx]) & (t_plt<=scan_stop_mjd[scan_idx]))[0]\n",
    "    extent = [scan_start_mjd[scan_idx][0],scan_stop_mjd[scan_idx][0],freq[0],freq[-1]]\n",
    "    \n",
    "    data_plot = 10*np.log10(LL_set[w,:].T)\n",
    "    if RFI_masked:\n",
    "        data_plot[RFI_mask_idx,:] = np.nan\n",
    "    \n",
    "    im = axs.imshow(data_plot,aspect='auto',vmin=power_min,vmax=power_max,\n",
    "                    origin='lower',extent=extent,cmap='viridis')\n",
    "\n",
    "    divider = make_axes_locatable(axs)\n",
    "    cax = divider.append_axes('right', size='2%', pad=0.05)\n",
    "    cbar = fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "    cbar.ax.tick_params(labelsize=fs) \n",
    "    cbar.set_label('Power (dB)', fontsize=fs)\n",
    "\n",
    "    axs.set_xlim(extent[0],extent[1])\n",
    "    axs.set_ylim(freq[0],freq[-1])\n",
    "    axs.tick_params(axis='both', labelsize=fs)\n",
    "    axs.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    axs.fmt_xdata = mdates.DateFormatter('%H:%M:%S')\n",
    "    axs.set_xlabel('Time (UTC)',fontsize=fs)        \n",
    "    axs.set_ylabel('Frequency (MHz)',fontsize=fs)\n",
    "    axs.set_title('Scan '+str(scan_id_plot)+' , el = '+str(scan_el[scan_idx[0][0]]),fontsize=fs)\n",
    "\n",
    "\n",
    "def DVA_Cross_Sections(freq_chosen, time_idx, freq_cross_section,RFI_masked):\n",
    "    \n",
    "    freq_measured = np.where(abs(freq-freq_chosen)<df)[0][0]\n",
    "    freq_below = np.where((freq>freq_chosen-5) & (freq<freq_chosen))[0]\n",
    "    freq_above = np.where((freq<freq_chosen+5) & (freq>freq_chosen))[0]\n",
    "   \n",
    "    fig,axs1 = plt.subplots(1,1,figsize=(16,6))  \n",
    "\n",
    "    if(freq_cross_section):\n",
    "        \n",
    "        data_plot_L = 10*np.log10(LL_set[time_idx,:])\n",
    "        data_plot_R = 10*np.log10(RR_set[time_idx,:])\n",
    "        \n",
    "        if RFI_masked:\n",
    "            data_plot_L[RFI_mask_idx] = np.nan\n",
    "            data_plot_R[RFI_mask_idx] = np.nan\n",
    "\n",
    "        axs1.plot(freq,data_plot_L,label='LL',color='blue')\n",
    "        axs1.plot(freq,data_plot_R,label='RR',color='red')        \n",
    "        axs1.vlines(freq_chosen, 0 , 100e9, color = 'purple')\n",
    "        axs1.set_ylim(power_min,power_max) \n",
    "        axs1.set_xlim(350,1050)\n",
    "        axs1.set_xlabel('Frequency',fontsize=fs)\n",
    "        axs1.tick_params(axis='both',labelsize=fs)\n",
    "    else:\n",
    "        axs1.scatter(t_plt, 10*np.log10(LL_set[:,freq_measured]),label='LL',s=0.8,zorder=1,color='blue')\n",
    "        axs1.scatter(t_plt, 10*np.log10(RR_set[:,freq_measured]),label='RR',s=0.8,zorder=1,color='red')\n",
    "          \n",
    "        axs1.vlines(t_plt[time_idx], 0 , 100e9, color = 'purple')\n",
    "        \n",
    "        for i in range(0,len(scan_id)):\n",
    "            if scan_el[i] == '49':\n",
    "                elclr = 'C0'\n",
    "            else:\n",
    "                elclr = 'C1'        \n",
    "            axs1.axvspan(scan_start_mjd[i],scan_stop_mjd[i],color=elclr,alpha=0.2,zorder=0)\n",
    "            axs1.text(scan_start_mjd[i]+3e-3,power_max+0.5,f\"{scan_id[i]:04}\",rotation=45,fontsize=fs)\n",
    "\n",
    "        axs1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "        axs1.set_ylim(power_min,power_max)\n",
    "        axs1.fmt_xdata = mdates.DateFormatter('%H:%M:%S')\n",
    "        axs1.set_xlabel('Time (UTC)',fontsize=fs)\n",
    "        axs1.set_xlim(t_plt[0],t_plt[-1])\n",
    "        axs1.tick_params(axis='both',labelsize=fs)\n",
    "        axs1.tick_params(axis='both',labelsize=fs)\n",
    "        \n",
    "        if freq_measured in RFI_mask_idx:\n",
    "            axs1.set_facecolor('lightgray')        \n",
    "        \n",
    "    axs1.set_ylabel('Power',fontsize=fs)\n",
    "    axs1.legend(fontsize=fs,markerscale=5)\n",
    "    axs1.grid()\n",
    "\n",
    "    \n",
    "def DVA_Cross_Sections_singlescan(freq_chosen,scan_chosen,RFI_masked,freq_cross_section,time_idx):\n",
    "    \n",
    "    freq_measured = np.where(abs(freq-freq_chosen)<df)[0][0]\n",
    "    freq_below = np.where((freq>freq_chosen-5) & (freq<freq_chosen))[0]\n",
    "    freq_above = np.where((freq<freq_chosen+5) & (freq>freq_chosen))[0]\n",
    "    #print(freq[freq_measured],freq[freq_range])\n",
    "          \n",
    "    scan_id_plot = scan_chosen\n",
    "    scan_idx = np.where(np.array(scan_id) == scan_id_plot)\n",
    "    \n",
    "    w = np.where((t_plt>=scan_start_mjd[scan_idx]) & (t_plt<=scan_stop_mjd[scan_idx]))[0]\n",
    "         \n",
    "    fig,axs1 = plt.subplots(1,1,figsize=(16,6)) \n",
    "            \n",
    "    if(freq_cross_section):\n",
    "            \n",
    "        data_plot_L = 10*np.log10(LL_set[w[time_idx],:])\n",
    "        data_plot_R = 10*np.log10(RR_set[w[time_idx],:])\n",
    "        \n",
    "        if RFI_masked:\n",
    "            data_plot_L[RFI_mask_idx] = np.nan\n",
    "            data_plot_R[RFI_mask_idx] = np.nan\n",
    "            \n",
    "        axs1.plot(freq,data_plot_L, label='LL',color='blue')\n",
    "        axs1.plot(freq,data_plot_R, label='RR',color='red')\n",
    "        axs1.vlines(freq_chosen, 0 , 100e9, color = 'purple')\n",
    "        axs1.set_ylim(power_min,power_max)\n",
    "        axs1.set_xlim(350,1030)\n",
    "        axs1.set_xlabel('Frequency',fontsize=fs)\n",
    "        axs1.tick_params(axis='both',labelsize=fs)\n",
    "    else:\n",
    "        axs1.plot(t_plt[w], 10*np.log10(LL_set[w,freq_measured]), label='LL',color='blue',zorder=1)\n",
    "        axs1.plot(t_plt[w], 10*np.log10(RR_set[w,freq_measured]), label='RR',color='red',zorder=1)\n",
    "        for ifreq in freq_above:\n",
    "            axs1.plot(t_plt[w], 10*np.log10(LL_set[w,ifreq]), alpha=0.5,color='C0',zorder=0)\n",
    "            axs1.plot(t_plt[w], 10*np.log10(RR_set[w,ifreq]), alpha=0.5,color='C1',zorder=0)\n",
    "        for ifreq in freq_below:\n",
    "            axs1.plot(t_plt[w], 10*np.log10(LL_set[w,ifreq]), alpha=0.5,color='C9',zorder=0)\n",
    "            axs1.plot(t_plt[w], 10*np.log10(RR_set[w,ifreq]), alpha=0.5,color='salmon',zorder=0)\n",
    "        axs1.vlines(t_plt[w][time_idx], 0 , 100e9, color = 'purple')\n",
    "\n",
    "        axs1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "        axs1.set_ylim(power_min,power_max) #AO changed this to log scale limits\n",
    "        axs1.fmt_xdata = mdates.DateFormatter('%H:%M:%S')\n",
    "        axs1.set_xlabel('Time (UTC)',fontsize=fs)\n",
    "        axs1.set_xlim(t_plt[w][0],t_plt[w][-1])\n",
    "        axs1.tick_params(axis='both',labelsize=fs)\n",
    "        axs1.set_title('Scan '+str(scan_id_plot)+' , el = '+str(scan_el[scan_idx[0][0]]),fontsize=fs)\n",
    "            \n",
    "        if freq_measured in RFI_mask_idx:\n",
    "             axs1.set_facecolor('lightgray')\n",
    "        \n",
    "    axs1.set_ylabel('Power',fontsize=fs)\n",
    "    axs1.legend(fontsize=fs,markerscale=5)\n",
    "    axs1.grid()  \n",
    "        \n",
    "def DVA_Visualization(waterfall_enabled,singlescan):    \n",
    "  \n",
    "    if waterfall_enabled:\n",
    "        if singlescan:\n",
    "            interact(DVA_Waterfall_View_singlescan,scan_chosen = scan_id, RFI_masked = False)\n",
    "        else:\n",
    "            interact(DVA_Waterfall_View, RFI_masked = False)\n",
    "    else:\n",
    "        if singlescan:\n",
    "            interact(DVA_Cross_Sections_singlescan, freq_chosen = (350, 1030, df), \n",
    "                     scan_chosen = scan_id, RFI_masked = False, freq_cross_section = False,\n",
    "                    time_idx = (0,1802))\n",
    "        else:\n",
    "            interact(DVA_Cross_Sections, freq_chosen = (350, 1030, df), \n",
    "                     freq_cross_section = False, time_idx = (0,len(t_plt)-1), RFI_masked = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2641ea3bc81940c0baa5306606a778cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=False, description='waterfall_enabled'), Checkbox(value=False, descriptioâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.DVA_Visualization(waterfall_enabled, singlescan)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(DVA_Visualization, waterfall_enabled = False, singlescan = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
