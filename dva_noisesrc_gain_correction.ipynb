{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply noise-diode-based gain corrections to azimuth and raster scans\n",
    "### A. Ordog, July 2022\n",
    "### NOTE: please do not modify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dva_sdhdf_combine\n",
    "import imp\n",
    "import os\n",
    "import subprocess\n",
    "import h5py\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "import datetime\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import HourLocator as HourLocator\n",
    "from matplotlib.dates import MinuteLocator as MinuteLocator\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from astropy import units as u\n",
    "from astropy.time import TimeDelta\n",
    "from scipy import interpolate\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "\n",
    "day ='14'\n",
    "\n",
    "#### Change the directory to where the files are located\" ####\n",
    "#dir_in = '/media/ordoga/DVA_data/survey_phase1_day'+day+'/'\n",
    "#dir_out = '/media/ordoga/DVA_data/survey_phase1_day'+day+'/'\n",
    "##############################################################\n",
    "\n",
    "### Use these directories on elephant: ###################\n",
    "dir_in_rast  = '/srv/data/dva/survey_raster/'\n",
    "dir_out_rast = '/srv/data/dva/survey_raster_gain_corr/'\n",
    "dir_in_az    = '/srv/data/dva/survey_azimuth_scans/'\n",
    "di_out_az    = '/srv/data/dva/survey_azimuth_scans_gain_corr/'\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in files listing start and stop times for azimuth and raster scans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_id = []    # The scan id number\n",
    "scan_start = []  # Start time of the scan (UTC)\n",
    "scan_stop = []   # Stop time of the scan (UTC)\n",
    "\n",
    "# Read in the azimuth scan data and store it in arrays:\n",
    "with open(dir_in_az+'DVAsurvey_phase1_day0'+day+'.txt') as fp:\n",
    "    for line in fp:       \n",
    "        scan_id.append(int(line.split()[0]))\n",
    "        scan_start.append(line.split()[1]+'T'+line.split()[2][0:12])\n",
    "        scan_stop.append(line.split()[3]+'T'+line.split()[4][0:12])\n",
    "        \n",
    "# Read in the raster scan data and store it in arrays:\n",
    "with open(dir_in_rast+'dva_survey_phase1_day0'+day+'_raster1.txt') as fp:\n",
    "    for line in fp:  \n",
    "        raster1_start = line.split()[3]\n",
    "        raster1_stop  = line.split()[4]\n",
    "with open(dir_in_rast+'dva_survey_phase1_day0'+day+'_raster2.txt') as fp:\n",
    "    for line in fp:  \n",
    "        raster2_start = line.split()[3]\n",
    "        raster2_stop  = line.split()[4]\n",
    "        \n",
    "print('raster 1:',raster1_start,raster1_stop)\n",
    "print('')\n",
    "for i in range(0,len(scan_id)):\n",
    "    print(f\"{scan_id[i]:04}\",scan_start[i],scan_stop[i])\n",
    "print('')\n",
    "print('raster 2:',raster2_start,raster2_stop)\n",
    "\n",
    "# Convert start and stop times to Modified Julian Day (MJD).\n",
    "scan_start_mjd = Time(scan_start, format='isot',scale='utc').mjd\n",
    "scan_stop_mjd  = Time(scan_stop,  format='isot',scale='utc').mjd\n",
    "raster1_start_mjd = Time(raster1_start, format='isot',scale='utc').mjd\n",
    "raster1_stop_mjd  = Time(raster1_stop,  format='isot',scale='utc').mjd\n",
    "raster2_start_mjd = Time(raster2_start, format='isot',scale='utc').mjd\n",
    "raster2_stop_mjd  = Time(raster2_stop,  format='isot',scale='utc').mjd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data and stitch together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def concatenate_data(file,RR,LL,reRL,imRL,trim,dec,ra,el,az,t,noise):\n",
    "    \n",
    "    dataset = file['data']['beam_0']['band_SB0']['scan_0']\n",
    "    trim_flag = dataset['metadata']['trim_scan_flag']\n",
    "    w = np.where(trim_flag == 0)[0]\n",
    "    \n",
    "    # Add the position and time data to the corresponding arrays:\n",
    "    dec = np.concatenate([dec,dataset['metadata']['declination'][w]])\n",
    "    ra = np.concatenate([ra,dataset['metadata']['right_ascension'][w]])\n",
    "    el = np.concatenate([el,dataset['metadata']['elevation'][w]])\n",
    "    az = np.concatenate([az,dataset['metadata']['azimuth'][w]])\n",
    "    t = np.concatenate([t,dataset['metadata']['utc'][w]])\n",
    "    noise = np.concatenate([noise,dataset['metadata']['noise_state'][w]])\n",
    "\n",
    "    # Add the spectrometer power data to the corresponding arrays:\n",
    "    RR = np.concatenate([RR,dataset['data'][w,0,:]],axis=0)\n",
    "    LL = np.concatenate([LL,dataset['data'][w,1,:]],axis=0)\n",
    "    reRL = np.concatenate([reRL,dataset['data'][w,2,:]],axis=0)\n",
    "    imRL = np.concatenate([imRL,dataset['data'][w,3,:]],axis=0)\n",
    "    \n",
    "    return RR,LL,reRL,imRL,trim,dec,ra,el,az,t,noise\n",
    "\n",
    "t = []\n",
    "az = []\n",
    "dec = []\n",
    "ra = []\n",
    "el = []\n",
    "noise = []\n",
    "trim_flag = []\n",
    "\n",
    "# Use one of the scans to get the list of frequencies:\n",
    "scan0 = f\"{scan_id[0]:04}\"\n",
    "file = h5py.File(dir_in_az+'dva_survey_raw_scan_'+scan0+'.h5','r')\n",
    "freq = file['data']['beam_0']['band_SB0']['frequency'][:]/1e6\n",
    "\n",
    "# Create empty arrays for the power data:\n",
    "RR = np.empty([0,len(freq)])\n",
    "LL = np.empty([0,len(freq)])\n",
    "reRL = np.empty([0,len(freq)])\n",
    "imRL = np.empty([0,len(freq)])\n",
    "\n",
    "# Raster scan 1:\n",
    "file = h5py.File(dir_in_rast+'dva_survey_phase1_day0'+day+'_raster1'+'.h5','r')\n",
    "RR,LL,reRL,imRL,trim_flag,dec,ra,el,az,t,noise = concatenate_data(file,RR,LL,reRL,imRL,trim_flag,dec,ra,el,az,t,noise)\n",
    "\n",
    "# Loop through all the scans in the \"scan_num\" list:\n",
    "for i in scan_id:\n",
    "    file = h5py.File(dir_in_az+'dva_survey_raw_scan_'+f\"{i:04}\"+'.h5','r')\n",
    "    print(i,file)\n",
    "    RR,LL,reRL,imRL,trim_flag,dec,ra,el,az,t,noise = concatenate_data(file,RR,LL,reRL,imRL,trim_flag,dec,ra,el,az,t,noise)\n",
    "    \n",
    "# Raster scan 2:\n",
    "file = h5py.File(dir_in_rast+'dva_survey_phase1_day0'+day+'_raster2'+'.h5','r')\n",
    "RR,LL,reRL,imRL,trim_flag,dec,ra,el,az,t,noise = concatenate_data(file,RR,LL,reRL,imRL,trim_flag,dec,ra,el,az,t,noise)\n",
    "\n",
    "t_set_plt = Time(t, format='isot',scale='utc').mjd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_to_num(month_name):\n",
    "    if month_name == 'Jan': month_num = '01'\n",
    "    if month_name == 'Feb': month_num = '02'\n",
    "    if month_name == 'Mar': month_num = '03'\n",
    "    if month_name == 'Apr': month_num = '04'\n",
    "    if month_name == 'May': month_num = '05'\n",
    "    if month_name == 'Jun': month_num = '06'\n",
    "    if month_name == 'Jul': month_num = '07'\n",
    "    if month_name == 'Aug': month_num = '08'\n",
    "    if month_name == 'Sep': month_num = '09'\n",
    "    if month_name == 'Oct': month_num = '10'\n",
    "    if month_name == 'Nov': month_num = '11'\n",
    "    if month_name == 'Dec': month_num = '12'\n",
    "    return(month_num)\n",
    "\n",
    "i = 0\n",
    "t_weath = []\n",
    "temp_C = []\n",
    "\n",
    "with open(\"/srv/data/dva/weather_survey_phase1.txt\") as fp:\n",
    "    for line in fp:\n",
    "        t_weath.append(str( line.split()[2]+'-'+month_to_num(line.split()[1])+'-'+line.split()[0]+\n",
    "                  'T'+line.split()[3]))\n",
    "        temp_C.append(line.split()[4])        \n",
    "\n",
    "temp_C = np.array(temp_C,dtype=float)\n",
    "t_weath_fix = Time(t_weath, format='isot',scale='utc')\n",
    "t_weath_plt = t_weath_fix.mjd\n",
    "\n",
    "#plt.plot(t_weath_plt,temp_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that the noise source was being fired where expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, axs = plt.subplots(3,1,figsize=(20,8))\n",
    "\n",
    "axs[0].scatter(t_set_plt,noise,s=5)\n",
    "axs[0].set_xlim(raster1_start_mjd,raster1_stop_mjd)\n",
    "axs2 = axs[0].twinx()\n",
    "axs2.plot(t_set_plt,dec,color='k')\n",
    "#axs2.set_xlim(raster1_start_mjd,raster1_stop_mjd)\n",
    "axs2.set_ylim(7.5,17)\n",
    "\n",
    "axs[1].scatter(t_set_plt,noise,s=5)\n",
    "axs[1].set_xlim(scan_start_mjd[0],scan_stop_mjd[-1])\n",
    "axs2 = axs[1].twinx()\n",
    "axs2.scatter(t_set_plt,az,color='k',s=0.1)\n",
    "#axs2.set_xlim(scan_start_mjd[0],scan_stop_mjd[-1])\n",
    "axs2.set_ylim(-20,380)\n",
    "\n",
    "axs[2].scatter(t_set_plt,noise,s=5)\n",
    "axs[2].set_xlim(raster2_start_mjd,raster2_stop_mjd)\n",
    "axs2 = axs[2].twinx()\n",
    "axs2.plot(t_set_plt,dec,color='k')\n",
    "#axs2.set_xlim(raster1_start_mjd,raster1_stop_mjd)\n",
    "axs2.set_ylim(36,46)\n",
    "\n",
    "for i in range(0,3):\n",
    "    axs[i].xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    axs[i].fmt_xdata = mdates.DateFormatter('%H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the gain at each noise source instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "# The number of integrations to include on either \n",
    "# side of each noise source instance:\n",
    "n_off = 5\n",
    "################################################\n",
    "\n",
    "# Make arrays for on and off noise source\n",
    "LL_noise = np.zeros_like(LL)\n",
    "LL_off = np.zeros_like(LL)\n",
    "t_noise = np.zeros_like(t_set_plt)\n",
    "\n",
    "wnoise = np.where(noise == 1)[0]\n",
    "for k,g in groupby(enumerate(wnoise),lambda x:x[0]-x[1]):\n",
    "\n",
    "    group = np.array(list(map(itemgetter(1),g)))\n",
    "    middle = [group[int(np.floor((len(group)-1)/2))] ,group[int(np.ceil((len(group)-1)/2))]]    \n",
    "    offleft = [group[0]-n_off,group[0]-1]\n",
    "    offright = [group[-1]+1,group[-1]+n_off]\n",
    "    \n",
    "    LL_noise[middle,:] = np.nanmean(LL[middle,:],axis=0)\n",
    "    LL_off[middle,:] = (np.nanmean(LL[offleft[0]:offleft[-1]+1,:],axis=0) + \n",
    "                        np.nanmean(LL[offright[0]:offright[-1]+1,:],axis=0))/2.\n",
    "    t_noise[middle] = t_set_plt[middle]\n",
    "\n",
    "LL_dnoise = LL_noise - LL_off\n",
    "wnoise_pt = np.where(t_noise > 0)[0]\n",
    "GL = LL_dnoise/np.nanmean(LL_dnoise[wnoise_pt,:],axis=0)\n",
    "GL_fix = GL.copy()\n",
    "\n",
    "print(LL_dnoise.shape)\n",
    "print(GL.shape)\n",
    "print(GL[wnoise_pt,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gthresh = 0.1\n",
    "fplot = 800\n",
    "\n",
    "df = freq[1]-freq[0]\n",
    "wf = np.where(abs(freq-fplot)<df/2)[0][0]\n",
    "print(freq[wf])\n",
    "\n",
    "j=0\n",
    "for i in range(1,GL_fix[wnoise_pt,:].shape[0]-1):\n",
    "    if GL_fix[wnoise_pt,:][i,wf] != 0:\n",
    "        print(i,j,abs(GL_fix[wnoise_pt,:][i,wf]-GL_fix[wnoise_pt,:][i-1,wf]),\n",
    "              abs(GL_fix[wnoise_pt,:][i,wf]-GL_fix[wnoise_pt,:][i+1,wf]))\n",
    "        j = j+1\n",
    "        if ( (abs(GL_fix[wnoise_pt,:][i,wf]-GL_fix[wnoise_pt,:][i-1,wf]) > Gthresh) or \n",
    "             (abs(GL_fix[wnoise_pt,:][i,wf]-GL_fix[wnoise_pt,:][i+1,wf]) > Gthresh) ) :\n",
    "            print('bad')\n",
    "            GL_fix[wnoise_pt,:][i,:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GL_int = np.empty_like(GL)\n",
    "for i in range(0,len(freq)):\n",
    "    fint = interpolate.interp1d(t_noise[wnoise_pt],GL[wnoise_pt,i] , kind = 'cubic',fill_value=\"extrapolate\")\n",
    "    GL_int[:,i] = fint(t_set_plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot power and gain for a single frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fplot = 800\n",
    "df = freq[1]-freq[0]\n",
    "wf = np.where(abs(freq-fplot)<df/2)[0][0]\n",
    "print(freq[wf])\n",
    "sz=1\n",
    "fig1, axs = plt.subplots(3,1,figsize=(20,12))\n",
    "\n",
    "for i in range(0,3):\n",
    "    axs[i].scatter(t_set_plt,LL[:,wf],s=sz)\n",
    "    #axs[i].scatter(t_set_plt,LL[:,wf]/GL_int[:,wf],s=sz,color='red')\n",
    "    #axs[i].scatter(t_set_plt,LL_noise[:,wf],s=sz)\n",
    "    #axs[i].scatter(t_set_plt,LL_off[:,wf],s=sz,color='k')\n",
    "    ax2 = axs[i].twinx()\n",
    "    ax2.scatter(t_set_plt,GL[:,wf],s=20,color='blue')\n",
    "    ax2.scatter(t_set_plt,GL_fix[:,wf],s=5,color='red')\n",
    "    #ax2.plot(t_set_plt,GL_int[:,wf],color='k')\n",
    "    ax2.set_ylim(0.7,1.3)\n",
    "    axs[i].xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    axs[i].fmt_xdata = mdates.DateFormatter('%H:%M:%S')\n",
    "    axs[i].grid()\n",
    "\n",
    "axs[0].set_xlim(raster1_start_mjd,raster1_stop_mjd)\n",
    "axs[0].set_ylim(0.5e7,3e7)\n",
    "axs[1].set_xlim(scan_start_mjd[0],scan_stop_mjd[-1])\n",
    "axs[1].set_ylim(0.5e7,3e7)\n",
    "axs[2].set_xlim(raster2_start_mjd,raster2_stop_mjd)\n",
    "axs[2].set_ylim(0.5e7,3e7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waterfall plot for power, gain and temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fplot = 800\n",
    "df = freq[1]-freq[0]\n",
    "wf = np.where(abs(freq-fplot)<df/2)[0][0]\n",
    "print(freq[wf])\n",
    "\n",
    "fig1, axs = plt.subplots(3,1,figsize=(20,18),sharex=True,gridspec_kw={'height_ratios': [1,1,0.5]},\n",
    "                         constrained_layout=True)\n",
    "fs = 16\n",
    "\n",
    "for i in range(0,len(scan_id)):\n",
    "    w = np.where((t_set_plt>=scan_start_mjd[i]) & (t_set_plt<=scan_stop_mjd[i]))[0]\n",
    "    extent = [scan_start_mjd[i],scan_stop_mjd[i],freq[0],freq[-1]]\n",
    "    \n",
    "    im1 = axs[0].imshow(10*np.log10(LL[w,:].T),aspect='auto',vmin=71,vmax=77,origin='lower',\n",
    "                        extent=extent,cmap='viridis')    \n",
    "    im2 = axs[1].imshow(GL_int[w,:].T,aspect='auto',vmin=0.7,vmax=1.3,origin='lower',\n",
    "                        extent=extent,cmap='RdBu')\n",
    "    \n",
    "w = np.where((t_set_plt>=raster1_start_mjd) & (t_set_plt<=raster1_stop_mjd))[0]\n",
    "extent = [raster1_start_mjd,raster1_stop_mjd,freq[0],freq[-1]]\n",
    "\n",
    "im1 = axs[0].imshow(10*np.log10(LL[w,:].T),aspect='auto',vmin=71,vmax=77,origin='lower',\n",
    "                    extent=extent,cmap='viridis')\n",
    "im2 = axs[1].imshow(GL_int[w,:].T,aspect='auto',vmin=0.7,vmax=1.3,origin='lower',\n",
    "                    extent=extent,cmap='RdBu')\n",
    "\n",
    "w = np.where((t_set_plt>=raster2_start_mjd) & (t_set_plt<=raster2_stop_mjd))[0]\n",
    "extent = [raster2_start_mjd,raster2_stop_mjd,freq[0],freq[-1]]\n",
    "\n",
    "im1 = axs[0].imshow(10*np.log10(LL[w,:].T),aspect='auto',vmin=71,vmax=77,origin='lower',\n",
    "                    extent=extent,cmap='viridis')\n",
    "im2 = axs[1].imshow(GL_int[w,:].T,aspect='auto',vmin=0.7,vmax=1.3,origin='lower',\n",
    "                    extent=extent,cmap='RdBu')\n",
    "\n",
    "cbar1= fig1.colorbar(im1,ax=axs[0])\n",
    "cbar1.ax.tick_params(labelsize=fs) \n",
    "cbar1.set_label('Power (dB)', fontsize=fs)\n",
    "\n",
    "cbar2 = fig1.colorbar(im2,ax=axs[1])\n",
    "cbar2.ax.tick_params(labelsize=fs) \n",
    "cbar2.set_label('Gain', fontsize=fs)\n",
    "\n",
    "axs[2].plot(t_weath_plt,temp_C,color='purple',linewidth=3)\n",
    "axs[2].set_ylim(-5,35)     \n",
    "axs[2].set_ylabel('Temperature (C)',fontsize=fs)\n",
    "axs[2].axvspan(raster1_start_mjd,raster1_stop_mjd,color='C0',alpha=0.1)\n",
    "axs[2].axvspan(raster2_start_mjd,raster2_stop_mjd,color='C0',alpha=0.1)\n",
    "ax2 = axs[2].twinx()\n",
    "ax2.scatter(t_set_plt,GL[:,wf],s=5,color='k')\n",
    "ax2.set_ylim(0.2,1.8)\n",
    "ax2.set_ylabel('Gain at 800 MHz',fontsize=fs)\n",
    "ax2.tick_params(axis='y', labelsize=fs)\n",
    "for i in range(0,len(scan_id)):\n",
    "    elhere = el[abs(t_set_plt-scan_start_mjd[i])<1e-4][0]\n",
    "    if abs(elhere-49.32)<0.5:\n",
    "        clr = 'C1'\n",
    "    elif abs(elhere-20.0)<0.5:\n",
    "        clr = 'C2'\n",
    "    axs[2].axvspan(scan_start_mjd[i],scan_stop_mjd[i],color=clr,alpha=0.1)\n",
    "axs[2].grid() \n",
    "\n",
    "for i in range(0,3):\n",
    "    axs[i].set_xlim(t_set_plt[0],t_set_plt[-1])\n",
    "    axs[i].tick_params(axis='both', labelsize=fs,labelbottom=True)\n",
    "    axs[i].xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    axs[i].fmt_xdata = mdates.DateFormatter('%H:%M:%S')\n",
    "    axs[i].set_xlabel('Time (UTC)',fontsize=fs)        \n",
    "for i in range(0,2):\n",
    "    axs[i].set_ylim(freq[0],freq[-1])\n",
    "    axs[i].set_ylabel('Frequency (MHz)',fontsize=fs)\n",
    "    \n",
    "#plt.tight_layout()\n",
    "plt.savefig('../DVA_PLOTS/gains_waterfall_phase1_day'+day+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
