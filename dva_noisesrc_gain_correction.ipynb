{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78851bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dva_sdhdf_combine\n",
    "import imp\n",
    "import os\n",
    "import subprocess\n",
    "import h5py\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "import datetime\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import HourLocator as HourLocator\n",
    "from matplotlib.dates import MinuteLocator as MinuteLocator\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from astropy import units as u\n",
    "from astropy.time import TimeDelta\n",
    "from scipy import interpolate\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "\n",
    "day ='06'\n",
    "\n",
    "#### Change the directory to where the files are located\" ####\n",
    "dir_in = '/media/ordoga/DVA_data/survey_phase1_day'+day+'/'\n",
    "dir_out = '/media/ordoga/DVA_data/survey_phase1_day'+day+'/'\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07936e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_id = []    # The scan id number\n",
    "scan_start = []  # Start time of the scan (UTC)\n",
    "scan_stop = []   # Stop time of the scan (UTC)\n",
    "\n",
    "# Read in the data and store it in arrays:\n",
    "with open(dir_in+'DVAsurvey_phase1_day0'+day+'.txt') as fp:\n",
    "    for line in fp:       \n",
    "        scan_id.append(int(line.split()[0]))\n",
    "        scan_start.append(line.split()[1]+'T'+line.split()[2][0:12])\n",
    "        scan_stop.append(line.split()[3]+'T'+line.split()[4][0:12])\n",
    "        \n",
    "# Print out the scan numbers with their start and stop times:\n",
    "for i in range(0,len(scan_id)):\n",
    "    print(f\"{scan_id[i]:04}\",scan_start[i],scan_stop[i])\n",
    "\n",
    "# Convert start and stop times to Modified Julian Day (MJD).\n",
    "# This is needed for plotting and for selecting out data collected\n",
    "# between particular times:\n",
    "scan_start_mjd = Time(scan_start, format='isot',scale='utc').mjd\n",
    "scan_stop_mjd  = Time(scan_stop,  format='isot',scale='utc').mjd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d09306",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dir_in+'dva_survey_phase1_day0'+day+'_raster1.txt') as fp:\n",
    "    for line in fp:  \n",
    "        raster1_start = line.split()[3]\n",
    "        raster1_stop  = line.split()[4]\n",
    "with open(dir_in+'dva_survey_phase1_day0'+day+'_raster2.txt') as fp:\n",
    "    for line in fp:  \n",
    "        raster2_start = line.split()[3]\n",
    "        raster2_stop  = line.split()[4]\n",
    "\n",
    "print(raster1_start)\n",
    "print(raster1_stop)\n",
    "print(raster2_start)\n",
    "print(raster2_stop)\n",
    "\n",
    "raster1_start_mjd = Time(raster1_start, format='isot',scale='utc').mjd\n",
    "raster1_stop_mjd  = Time(raster1_stop,  format='isot',scale='utc').mjd\n",
    "raster2_start_mjd = Time(raster2_start, format='isot',scale='utc').mjd\n",
    "raster2_stop_mjd  = Time(raster2_stop,  format='isot',scale='utc').mjd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5329426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "t_set = []\n",
    "az_set = []\n",
    "dec_set = []\n",
    "ra_set = []\n",
    "el_set = []\n",
    "noise_set = []\n",
    "trim_flag = []\n",
    "\n",
    "scan0 = f\"{scan_id[0]:04}\"\n",
    "\n",
    "# Use one of the scans to get the list of frequencies:\n",
    "file = h5py.File(dir_in+'dva_survey_raw_scan_'+scan0+'.h5','r')\n",
    "freq = file['data']['beam_0']['band_SB0']['frequency'][::12]/1e6\n",
    "\n",
    "# Create empty arrays for the power data:\n",
    "RR_set = np.empty([0,len(freq)])\n",
    "LL_set = np.empty([0,len(freq)])\n",
    "reRL_set = np.empty([0,len(freq)])\n",
    "imRL_set = np.empty([0,len(freq)])\n",
    "\n",
    "# Raster scan 1:\n",
    "file = h5py.File(dir_in+'dva_survey_phase1_day0'+day+'_raster1'+'.h5','r')\n",
    "dataset = file['data']['beam_0']['band_SB0']['scan_0']\n",
    "trim_flag = dataset['metadata']['trim_scan_flag']\n",
    "w = np.where(trim_flag == 0)[0]\n",
    "# Add the position and time data to the corresponding arrays:\n",
    "dec_set = np.concatenate([dec_set,dataset['metadata']['declination'][w]])\n",
    "ra_set = np.concatenate([ra_set,dataset['metadata']['right_ascension'][w]])\n",
    "el_set = np.concatenate([el_set,dataset['metadata']['elevation'][w]])\n",
    "az_set = np.concatenate([az_set,dataset['metadata']['azimuth'][w]])\n",
    "t_set = np.concatenate([t_set,dataset['metadata']['utc'][w]])\n",
    "noise_set = np.concatenate([noise_set,dataset['metadata']['noise_state'][w]])\n",
    "\n",
    "# Add the spectrometer power data to the corresponding arrays:\n",
    "RR_set = np.concatenate([RR_set,dataset['data'][w,0,::12]],axis=0)\n",
    "LL_set = np.concatenate([LL_set,dataset['data'][w,1,::12]],axis=0)\n",
    "reRL_set = np.concatenate([reRL_set,dataset['data'][w,2,::12]],axis=0)\n",
    "imRL_set = np.concatenate([imRL_set,dataset['data'][w,3,::12]],axis=0)\n",
    "\n",
    "\n",
    "# Loop through all the scans in the \"scan_num\" list:\n",
    "for i in scan_id:\n",
    "    print(i)\n",
    "    # select the file:\n",
    "    file = h5py.File(dir_in+'dva_survey_raw_scan_'+f\"{i:04}\"+'.h5','r')\n",
    "    print(file)\n",
    "    \n",
    "    # access the correct location in the file structure:\n",
    "    dataset = file['data']['beam_0']['band_SB0']['scan_0']\n",
    "    trim_flag = dataset['metadata']['trim_scan_flag']\n",
    "    w = np.where(trim_flag == 0)[0]\n",
    "    \n",
    "    # Add the position and time data to the corresponding arrays:\n",
    "    dec_set = np.concatenate([dec_set,dataset['metadata']['declination'][w]])\n",
    "    ra_set = np.concatenate([ra_set,dataset['metadata']['right_ascension'][w]])\n",
    "    el_set = np.concatenate([el_set,dataset['metadata']['elevation'][w]])\n",
    "    az_set = np.concatenate([az_set,dataset['metadata']['azimuth'][w]])\n",
    "    t_set = np.concatenate([t_set,dataset['metadata']['utc'][w]])\n",
    "    noise_set = np.concatenate([noise_set,dataset['metadata']['noise_state'][w]])\n",
    "    \n",
    "    # Add the spectrometer power data to the corresponding arrays:\n",
    "    RR_set = np.concatenate([RR_set,dataset['data'][w,0,::12]],axis=0)\n",
    "    LL_set = np.concatenate([LL_set,dataset['data'][w,1,::12]],axis=0)\n",
    "    reRL_set = np.concatenate([reRL_set,dataset['data'][w,2,::12]],axis=0)\n",
    "    imRL_set = np.concatenate([imRL_set,dataset['data'][w,3,::12]],axis=0)\n",
    "    \n",
    "    \n",
    "# Raster scan 2:\n",
    "file = h5py.File(dir_in+'dva_survey_phase1_day0'+day+'_raster2'+'.h5','r')\n",
    "dataset = file['data']['beam_0']['band_SB0']['scan_0']\n",
    "trim_flag = dataset['metadata']['trim_scan_flag']\n",
    "w = np.where(trim_flag == 0)[0]\n",
    "# Add the position and time data to the corresponding arrays:\n",
    "dec_set = np.concatenate([dec_set,dataset['metadata']['declination'][w]])\n",
    "ra_set = np.concatenate([ra_set,dataset['metadata']['right_ascension'][w]])\n",
    "el_set = np.concatenate([el_set,dataset['metadata']['elevation'][w]])\n",
    "az_set = np.concatenate([az_set,dataset['metadata']['azimuth'][w]])\n",
    "t_set = np.concatenate([t_set,dataset['metadata']['utc'][w]])\n",
    "noise_set = np.concatenate([noise_set,dataset['metadata']['noise_state'][w]])\n",
    "\n",
    "# Add the spectrometer power data to the corresponding arrays:\n",
    "RR_set = np.concatenate([RR_set,dataset['data'][w,0,::12]],axis=0)\n",
    "LL_set = np.concatenate([LL_set,dataset['data'][w,1,::12]],axis=0)\n",
    "reRL_set = np.concatenate([reRL_set,dataset['data'][w,2,::12]],axis=0)\n",
    "imRL_set = np.concatenate([imRL_set,dataset['data'][w,3,::12]],axis=0)\n",
    "    \n",
    "t_set_plt = Time(t_set, format='isot',scale='utc').mjd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fda1e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b8381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, axs = plt.subplots(3,1,figsize=(20,12))\n",
    "\n",
    "axs[0].scatter(t_set_plt,noise_set,s=5)\n",
    "axs[0].set_xlim(raster1_start_mjd,raster1_stop_mjd)\n",
    "axs2 = axs[0].twinx()\n",
    "axs2.plot(t_set_plt,dec_set,color='k')\n",
    "#axs2.set_xlim(raster1_start_mjd,raster1_stop_mjd)\n",
    "axs2.set_ylim(7.5,17)\n",
    "\n",
    "axs[1].scatter(t_set_plt,noise_set,s=5)\n",
    "axs[1].set_xlim(scan_start_mjd[0],scan_stop_mjd[-1])\n",
    "axs2 = axs[1].twinx()\n",
    "axs2.scatter(t_set_plt,az_set,color='k',s=0.1)\n",
    "#axs2.set_xlim(scan_start_mjd[0],scan_stop_mjd[-1])\n",
    "axs2.set_ylim(-20,380)\n",
    "\n",
    "axs[2].scatter(t_set_plt,noise_set,s=5)\n",
    "axs[2].set_xlim(raster2_start_mjd,raster2_stop_mjd)\n",
    "axs2 = axs[2].twinx()\n",
    "axs2.plot(t_set_plt,dec_set,color='k')\n",
    "#axs2.set_xlim(raster1_start_mjd,raster1_stop_mjd)\n",
    "axs2.set_ylim(36,46)\n",
    "\n",
    "for i in range(0,3):\n",
    "    axs[i].xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    axs[i].fmt_xdata = mdates.DateFormatter('%H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834adeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(LL_set.shape)\n",
    "#print(freq.shape)\n",
    "#print(t_set_plt.shape)\n",
    "#print(noise_set.shape)\n",
    "n_off = 5\n",
    "\n",
    "LL_noise = np.zeros_like(LL_set)\n",
    "LL_off = np.zeros_like(LL_set)\n",
    "t_noise = np.zeros_like(t_set_plt)\n",
    "\n",
    "wnoise = np.where(noise_set == 1)[0]\n",
    "for k,g in groupby(enumerate(wnoise),lambda x:x[0]-x[1]):\n",
    "\n",
    "    group = np.array(list(map(itemgetter(1),g)))\n",
    "    middle = [group[int(np.floor((len(group)-1)/2))] ,group[int(np.ceil((len(group)-1)/2))]]    \n",
    "    offleft = [group[0]-n_off,group[0]-1]\n",
    "    offright = [group[-1]+1,group[-1]+n_off]\n",
    "    \n",
    "    LL_noise[middle,:] = np.nanmean(LL_set[middle,:],axis=0)\n",
    "    LL_off[middle,:] = (np.nanmean(LL_set[offleft[0]:offleft[-1]+1,:],axis=0) + \n",
    "                        np.nanmean(LL_set[offright[0]:offright[-1]+1,:],axis=0))/2.\n",
    "    t_noise[middle] = t_set_plt[middle]\n",
    "\n",
    "LL_dnoise = LL_noise - LL_off\n",
    "wnoise_pt = np.where(t_noise > 0)[0]\n",
    "GL = LL_dnoise/np.nanmean(LL_dnoise[wnoise_pt,:],axis=0)\n",
    "\n",
    "print(LL_dnoise.shape)\n",
    "print(GL.shape)\n",
    "\n",
    "print(t_noise)\n",
    "print(t_noise[wnoise_pt].shape)\n",
    "print(GL[wnoise_pt,:].shape)\n",
    "\n",
    "GL_int = np.empty_like(GL)\n",
    "for i in range(0,len(freq)):\n",
    "    fint = interpolate.interp1d(t_noise[wnoise_pt],GL[wnoise_pt,i] , kind = 'cubic',fill_value=\"extrapolate\")\n",
    "    GL_int[:,i] = fint(t_set_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fplot = 800\n",
    "df = freq[1]-freq[0]\n",
    "wf = np.where(abs(freq-fplot)<df/2)[0][0]\n",
    "print(freq[wf])\n",
    "sz=1\n",
    "fig1, axs = plt.subplots(3,1,figsize=(20,12))\n",
    "\n",
    "axs[0].scatter(t_set_plt,LL_set[:,wf],s=sz)\n",
    "axs[0].scatter(t_set_plt,LL_set[:,wf]/GL_int[:,wf],s=sz,color='red')\n",
    "axs[0].scatter(t_set_plt,LL_noise[:,wf],s=sz)\n",
    "axs[0].scatter(t_set_plt,LL_off[:,wf],s=sz,color='k')\n",
    "ax2 = axs[0].twinx()\n",
    "ax2.scatter(t_set_plt,GL[:,wf],s=5,color='k')\n",
    "ax2.plot(t_set_plt,GL_int[:,wf],color='k')\n",
    "axs[0].set_xlim(raster1_start_mjd,raster1_stop_mjd)\n",
    "axs[0].set_ylim(0.5e7,2e7)\n",
    "\n",
    "axs[1].scatter(t_set_plt,LL_set[:,wf],s=sz)\n",
    "axs[1].scatter(t_set_plt,LL_set[:,wf]/GL_int[:,wf],s=sz,color='red')\n",
    "axs[1].scatter(t_set_plt,LL_noise[:,wf],s=sz)\n",
    "axs[1].scatter(t_set_plt,LL_off[:,wf],s=sz,color='k')\n",
    "ax2 = axs[1].twinx()\n",
    "ax2.scatter(t_set_plt,GL[:,wf],s=5,color='k')\n",
    "ax2.plot(t_set_plt,GL_int[:,wf],color='k')\n",
    "axs[1].set_xlim(scan_start_mjd[0],scan_stop_mjd[-1])\n",
    "axs[1].set_ylim(0.5e7,3e7)\n",
    "\n",
    "axs[2].scatter(t_set_plt,LL_set[:,wf],s=sz)\n",
    "axs[2].scatter(t_set_plt,LL_set[:,wf]/GL_int[:,wf],s=sz,color='red')\n",
    "axs[2].scatter(t_set_plt,LL_noise[:,wf],s=sz)\n",
    "axs[2].scatter(t_set_plt,LL_off[:,wf],s=sz,color='k')\n",
    "ax2 = axs[2].twinx()\n",
    "ax2.scatter(t_set_plt,GL[:,wf],s=5,color='k')\n",
    "ax2.plot(t_set_plt,GL_int[:,wf],color='k')\n",
    "axs[2].set_xlim(raster2_start_mjd,raster2_stop_mjd)\n",
    "axs[2].set_ylim(0.5e7,3.5e7)\n",
    "\n",
    "for i in range(0,3):\n",
    "    axs[i].xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    axs[i].fmt_xdata = mdates.DateFormatter('%H:%M:%S')\n",
    "    axs[i].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f8cb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnoiseLL[i,:] = np.nanmean(LL_set[wnoise_sub,:],axis=0)\n",
    "pnoiseRR[i,:] = np.nanmean(RR_set[wnoise_sub,:],axis=0)\n",
    "#poffLL[i,:] = np.nanmean(LL_set[list(woff1)+list(woff2),:],axis=0)\n",
    "#poffRR[i,:] = np.nanmean(RR_set[list(woff1)+list(woff2),:],axis=0)\n",
    "tnoise[i] = np.nanmean(t_plt[wnoise_sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8250a25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
