{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38cef3b6",
   "metadata": {},
   "source": [
    "## Read in separate raw data files and create files of individual azimuth scans\n",
    "### A. Ordog, June 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffc3dcd",
   "metadata": {},
   "source": [
    "## Import packages and define survey day and file directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aa737b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dva_sdhdf_combine_v3\n",
    "import imp\n",
    "import os\n",
    "import subprocess\n",
    "import h5py\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "import datetime\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import HourLocator as HourLocator\n",
    "from matplotlib.dates import MinuteLocator as MinuteLocator\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from astropy import units as u\n",
    "from astropy.time import TimeDelta\n",
    "from astropy.modeling import models, fitting\n",
    "\n",
    "day ='25'\n",
    "\n",
    "#### Change the directory to where the files are located\" ####\n",
    "directory = '../DVA/Data_Files/DVA_Day_Surveys/'#+day+'/'\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7a8343",
   "metadata": {},
   "source": [
    "## Read in the file listing azimuth scan start and stop times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "260ad1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052 2022-07-04T03:57:53.110 2022-07-04T04:15:55.184\n",
      "2565 2022-07-04T04:20:37.406 2022-07-04T04:38:39.310\n",
      "2566 2022-07-04T04:40:22.266 2022-07-04T04:58:24.003\n",
      "1271 2022-07-04T05:03:42.716 2022-07-04T05:21:44.818\n",
      "1272 2022-07-04T05:23:27.291 2022-07-04T05:41:29.292\n",
      "2857 2022-07-04T05:48:35.269 2022-07-04T06:06:37.317\n",
      "0124 2022-07-04T06:11:19.190 2022-07-04T06:29:21.101\n",
      "1637 2022-07-04T06:34:03.920 2022-07-04T06:52:06.005\n",
      "0342 2022-07-04T06:57:23.897 2022-07-04T07:15:25.930\n",
      "1927 2022-07-04T07:21:55.804 2022-07-04T07:39:58.034\n",
      "1928 2022-07-04T07:42:16.530 2022-07-04T08:00:18.319\n",
      "2001 2022-07-04T08:03:48.814 2022-07-04T08:21:51.062\n",
      "2002 2022-07-04T08:24:09.373 2022-07-04T08:42:11.545\n",
      "2075 2022-07-04T08:45:41.821 2022-07-04T09:03:44.188\n",
      "2148 2022-07-04T09:07:50.625 2022-07-04T09:25:52.832\n",
      "2149 2022-07-04T09:27:35.229 2022-07-04T09:45:37.044\n",
      "2150 2022-07-04T09:47:56.026 2022-07-04T10:05:57.828\n",
      "2151 2022-07-04T10:07:40.752 2022-07-04T10:25:42.662\n",
      "2152 2022-07-04T10:27:25.410 2022-07-04T10:45:27.414\n",
      "2153 2022-07-04T10:47:46.110 2022-07-04T11:05:48.028\n",
      "0858 2022-07-04T11:10:30.298 2022-07-04T11:28:32.281\n",
      "0859 2022-07-04T11:30:50.747 2022-07-04T11:48:52.934\n",
      "2372 2022-07-04T11:53:35.348 2022-07-04T12:11:37.677\n"
     ]
    }
   ],
   "source": [
    "scan_id = []    # The scan id number\n",
    "scan_start = []  # Start time of the scan (UTC)\n",
    "scan_stop = []   # Stop time of the scan (UTC)\n",
    "\n",
    "# Read in the data and store it in arrays:\n",
    "with open(directory+'DVAsurvey_phase1_day0'+day+'.txt') as fp:\n",
    "    for line in fp:       \n",
    "        scan_id.append(int(line.split()[0]))\n",
    "        scan_start.append(line.split()[1]+'T'+line.split()[2][0:12])\n",
    "        scan_stop.append(line.split()[3]+'T'+line.split()[4][0:12])\n",
    "        \n",
    "# Print out the scan numbers with their start and stop times:\n",
    "for i in range(0,len(scan_id)):\n",
    "    print(f\"{scan_id[i]:04}\",scan_start[i],scan_stop[i])\n",
    "\n",
    "# Convert start and stop times to Modified Julian Day (MJD).\n",
    "# This is needed for plotting and for selecting out data collected\n",
    "# between particular times:\n",
    "scan_start_mjd = Time(scan_start, format='isot',scale='utc').mjd\n",
    "scan_stop_mjd  = Time(scan_stop,  format='isot',scale='utc').mjd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398fa053",
   "metadata": {},
   "source": [
    "## Make files for each azimuth scan:Â¶\n",
    "### ***Note: skip this if files already made\n",
    "##### grey = all data  \n",
    "##### orange = RA changing too much \n",
    "##### green = outside of scan time\n",
    "##### black = good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df618040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# imp.reload(dva_sdhdf_combine_v3)\n",
    "\n",
    "# for i in range(0,len(scan_id)):\n",
    "# #for i in range(0,5):\n",
    "#     print('===============================')\n",
    "#     print('Making scan ',i+1,' out of ',len(scan_id),' (scan id =',scan_id[i],') for times:')\n",
    "#     print(scan_start[i],scan_stop[i])\n",
    "#     print('===============================')\n",
    "#     print('')\n",
    "#     outname = 'dva_survey_raw_scan_'+f\"{int(scan_id[i]):04}\"\n",
    "#     dva_sdhdf_combine_v3.combine(directory,directory,scan_start[i],scan_stop[i],outname,freq_s=2,\n",
    "#                                  az_scan_trim=True,freq_avg=True)\n",
    "#     print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc507b4",
   "metadata": {},
   "source": [
    "## Read in scan files and stitch them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cfed1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052\n",
      "<HDF5 file \"dva_survey_raw_scan_1052.h5\" (mode r)>\n",
      "2565\n",
      "<HDF5 file \"dva_survey_raw_scan_2565.h5\" (mode r)>\n",
      "2566\n",
      "<HDF5 file \"dva_survey_raw_scan_2566.h5\" (mode r)>\n",
      "1271\n",
      "<HDF5 file \"dva_survey_raw_scan_1271.h5\" (mode r)>\n",
      "1272\n",
      "<HDF5 file \"dva_survey_raw_scan_1272.h5\" (mode r)>\n",
      "[b'2022-07-04T03:57:53.200004Z' b'2022-07-04T03:57:53.800004Z'\n",
      " b'2022-07-04T03:57:54.400004Z' ... b'2022-07-04T05:41:28.000004Z'\n",
      " b'2022-07-04T05:41:28.600004Z' b'2022-07-04T05:41:29.200004Z']\n",
      "Wall time: 6.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "t_set = []\n",
    "az_set = []\n",
    "dec_set = []\n",
    "ra_set = []\n",
    "el_set = []\n",
    "noise_set = []\n",
    "trim_flag = []\n",
    "\n",
    "scan0 = f\"{scan_id[0]:04}\"\n",
    "\n",
    "# Use one of the scans to get the list of frequencies:\n",
    "file = h5py.File(directory+'dva_survey_raw_scan_'+scan0+'.h5','r')\n",
    "freq = file['data']['beam_0']['band_SB0']['frequency'][::12]/1e6\n",
    "\n",
    "# Create empty arrays for the power data:\n",
    "RR_set = np.empty([0,len(freq)])\n",
    "LL_set = np.empty([0,len(freq)])\n",
    "reRL_set = np.empty([0,len(freq)])\n",
    "imRL_set = np.empty([0,len(freq)])\n",
    "\n",
    "# Loop through all the scans in the \"scan_num\" list:\n",
    "for i in scan_id[0:5]:\n",
    "    print(i)\n",
    "    # select the file:\n",
    "    file = h5py.File(directory+'dva_survey_raw_scan_'+f\"{i:04}\"+'.h5','r')\n",
    "    print(file)\n",
    "    \n",
    "    # access the correct location in the file structure:\n",
    "    dataset = file['data']['beam_0']['band_SB0']['scan_0']\n",
    "    \n",
    "    # Add the position and time data to the corresponding arrays:\n",
    "    dec_set = np.concatenate([dec_set,dataset['metadata']['declination']])\n",
    "    ra_set = np.concatenate([ra_set,dataset['metadata']['right_ascension']])\n",
    "    el_set = np.concatenate([el_set,dataset['metadata']['elevation']])\n",
    "    az_set = np.concatenate([az_set,dataset['metadata']['azimuth']])\n",
    "    t_set = np.concatenate([t_set,dataset['metadata']['utc']])\n",
    "    noise_set = np.concatenate([noise_set,dataset['metadata']['noise_state']]) #This is a \"mask\" for noise regions 1 = noise 0=all good\n",
    "    trim_flag = np.concatenate([trim_flag,dataset['metadata']['trim_scan_flag']])\n",
    "    \n",
    "    # Add the spectrometer power data to the corresponding arrays:\n",
    "    freq_channel_increment = 12 #TODO: I'll have to change this to 1 once I am sure I'm reading the data correctly\n",
    "    RR_set = np.concatenate([RR_set,dataset['data'][:,0,::freq_channel_increment]],axis=0)\n",
    "    LL_set = np.concatenate([LL_set,dataset['data'][:,1,::freq_channel_increment]],axis=0)\n",
    "    reRL_set = np.concatenate([reRL_set,dataset['data'][:,2,::freq_channel_increment]],axis=0)\n",
    "    imRL_set = np.concatenate([imRL_set,dataset['data'][:,3,::freq_channel_increment]],axis=0)\n",
    "    \n",
    "print(t_set)\n",
    "t_set_plt = Time(t_set, format='isot',scale='utc').mjd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a816f6c0",
   "metadata": {},
   "source": [
    "## Make numpy files for daily data:\n",
    "#### This is just to produce a quick daily 'map' of the sky at two frequencies with scans we have so far.\n",
    "#### Code for making the map is in a separate notebook (daily_map.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349c902b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't_set_plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-384672406e5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mel_set_trim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mel_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mt_set_trim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mt_set_plt_trim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt_set_plt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mnoise_set_trim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnoise_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mRR_set_trim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRR_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 't_set_plt' is not defined"
     ]
    }
   ],
   "source": [
    "# ra_set_trim = ra_set.copy()\n",
    "# dec_set_trim = dec_set.copy()\n",
    "# az_set_trim = az_set.copy()\n",
    "# el_set_trim = el_set.copy()\n",
    "# t_set_trim = t_set.copy()\n",
    "# t_set_plt_trim = t_set_plt.copy()\n",
    "# noise_set_trim = noise_set.copy()\n",
    "# RR_set_trim = RR_set.copy()\n",
    "# LL_set_trim = LL_set.copy()\n",
    "# reRL_set_trim = reRL_set.copy()\n",
    "# imRL_set_trim = imRL_set.copy()\n",
    "\n",
    "# idxtrim = np.where(trim_flag == 1)[0]\n",
    "# print(idxtrim)\n",
    "\n",
    "# ra_set_trim[idxtrim] = np.nan\n",
    "# dec_set_trim[idxtrim] = np.nan \n",
    "# az_set_trim[idxtrim] = np.nan \n",
    "# el_set_trim[idxtrim] = np.nan \n",
    "# t_set_trim[idxtrim] = np.nan \n",
    "# t_set_plt_trim[idxtrim] = np.nan \n",
    "# noise_set_trim[idxtrim] = np.nan \n",
    "# RR_set_trim[idxtrim,:] = np.nan \n",
    "# LL_set_trim[idxtrim,:] = np.nan \n",
    "# reRL_set_trim[idxtrim,:] = np.nan \n",
    "# imRL_set_trim[idxtrim,:] = np.nan\n",
    "\n",
    "# df = freq[1]-freq[0]\n",
    "\n",
    "# freq_plt = 800. # in MHz\n",
    "# wf = np.where(abs(freq-freq_plt)<df)[0][0]\n",
    "# np.save('../DATA/Daily_maps/survey_phase1_all_800_day'+day+'.npy',([RR_set_trim[:,wf],LL_set_trim[:,wf],ra_set_trim,\n",
    "#                                                                     dec_set_trim,az_set_trim,el_set_trim,t_set_trim,\n",
    "#                                                                     noise_set_trim,t_set_plt_trim]))\n",
    "# freq_plt = 400. # in MHz\n",
    "# wf = np.where(abs(freq-freq_plt)<df)[0][0]\n",
    "# np.save('../DATA/Daily_maps/survey_phase1_all_400_day'+day+'.npy',([RR_set_trim[:,wf],LL_set_trim[:,wf],ra_set_trim,\n",
    "#                                                                     dec_set_trim,az_set_trim,el_set_trim,t_set_trim,\n",
    "#                                                                     noise_set_trim,t_set_plt_trim]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995eb034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a77f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bce62ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5bbb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a39a155",
   "metadata": {},
   "source": [
    "## Old code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80de3e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_plt = 800. # in MHz\n",
    "df = freq[1]-freq[0]\n",
    "wf = np.where(abs(freq-freq_plt)<df)[0][0]\n",
    "\n",
    "fs = 12\n",
    "fig1, axs = plt.subplots(23,1,figsize=(15,18))\n",
    "\n",
    "for i in range(0,23):\n",
    "    axs[i].plot(t_set_plt,LL_set[:,wf])\n",
    "    axs[i].set_xlim(scan_start_mjd[i],scan_stop_mjd[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792cf4e7",
   "metadata": {},
   "source": [
    "## Read in single scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4991aff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "file = h5py.File(directory+'dva_survey_raw_scan_'+f\"{scan_id[i]:04}\"+'.h5','r')\n",
    "print(file)\n",
    "    \n",
    "freq = file['data']['beam_0']['band_SB0']['frequency'][:]/1e6\n",
    "    \n",
    "# access the correct location in the file structure:\n",
    "dataset = file['data']['beam_0']['band_SB0']['scan_0']\n",
    "    \n",
    "# Add the position and time data to the corresponding arrays:\n",
    "dec1 = dataset['metadata']['declination']\n",
    "ra1 = dataset['metadata']['right_ascension']\n",
    "el1 = dataset['metadata']['elevation']\n",
    "az1 = dataset['metadata']['azimuth']\n",
    "t1 = dataset['metadata']['utc']\n",
    "noise1 = dataset['metadata']['noise_state']\n",
    "    \n",
    "    # Add the spectrometer power data to the corresponding arrays:\n",
    "RR1 = dataset['data'][:,0,:]\n",
    "LL1 = dataset['data'][:,1,:]\n",
    "reRL1 = dataset['data'][:,2,:]\n",
    "imRL1 = dataset['data'][:,3,:]\n",
    "\n",
    "ra1_deg = ra1*360./24.\n",
    "t1_plt = Time(t1, format='isot',scale='utc').mjd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdfef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((t1_plt[-1]-t1_plt[0])*24*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d47be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(t1)-1):\n",
    "    #print((t1_plt[i+1]-t1_plt[i])*24*3600)\n",
    "    print(ra1[i],ra1[i+1]-ra1[i])\n",
    "    #print(dec1[i+1]-dec1[i],ra1[i+1]-ra1[i],el1[i+1]-el1[i],az1[i+1]-az1[i],t1_plt[i+1]-t1_plt[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820d20d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 16\n",
    "fig1, axs = plt.subplots(1,1,figsize=(20,8))\n",
    "axs.scatter(ra1_deg, dec1,s=2,c=10.*np.log10(LL1[:,14000]),cmap='viridis',vmin=70.5, vmax=72)\n",
    "axs.set_xlabel('RA (hours)',fontsize=fs)\n",
    "axs.set_ylabel('Declination (degrees)',fontsize=fs)\n",
    "axs.tick_params(axis=\"x\", labelsize=fs)\n",
    "axs.tick_params(axis=\"y\", labelsize=fs)\n",
    "axs.set_xticks([0,45,90,135,180,225,270,315,360])\n",
    "axs.set_xticklabels(['0','3','6','9','12','15','18','21','24'])\n",
    "axs.set_xlim(360,0)\n",
    "axs.set_ylim(-30,90)\n",
    "axs.set(aspect='equal')\n",
    "axs.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e083e91b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
